{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbd68ab3-f04b-434f-a956-e730535c9ee5",
   "metadata": {},
   "source": [
    "## TAA2: Natural Hazard Risk Assessment using public data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cc742-23a7-4895-8d2a-7e826d8a23b8",
   "metadata": {},
   "source": [
    "Within this tutorial, we are going to use publicly available hazard data and exposure data to do a risk assessment for the Netherlands. More specifically we will look at damage due to wind storms and flooding. We will use both Copernicus Land Cover data and OpenStreetMap to estimate the potential damage of natural hazards to the built environment.\n",
    " \n",
    "We will first download, access and explore hazard data retrieved from the Copernicus Climate Data Copernicus Store and the European Commission Joint Research Centre. After this, we will learn how to download and access Copernicus Land Cover data. We will also explore the power of OpenStreetMap that provides vector data. We will learn how to extract information from OpenStreetMap, how you can explore and visualize this. Lastly, we will use Copernicus Land Cover data to estimate the damage to specific land-uses, whereas we will use OpenStreetMap to assess the potential damage to the road system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4355fca9-3e21-4556-a5d0-3e1577c68643",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dd18de-459a-4cb4-891e-cc3c98e76e7a",
   "metadata": {},
   "source": [
    "- To understand the use of **OSMnx** to extract geospatial data from OpenStreetmap.\n",
    "- To know how to download data from the Copernicus Climate Data Store using the `cdsapi` and access it through Python.\n",
    "- To know how to access and open information from the Copernicus Land Monitoring System. Specifically the Corine Land Cover data.\n",
    "\n",
    "- To be able to open and visualize this hazard data.\n",
    "- To know how to rasterize vector data through using **Geocube**.\n",
    "- To know how to visualise vector and raster data.\n",
    "- To understand the basic functioning of **Matplotlib** to create a map.\n",
    "\n",
    "- To understand the basic approach of a natural hazard risk assessment.\n",
    "- To be able to use the `DamageScanner` to do a damage assessment.\n",
    "- To interpret and compare the damage estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7cd45-4394-44fb-ba1b-e52464223d42",
   "metadata": {},
   "source": [
    "## 1. Introducing the packages\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d01ad-b5d4-4486-9d00-04fd00142a19",
   "metadata": {},
   "source": [
    "Within this tutorial, we are going to make use of the following packages: \n",
    "\n",
    "[**GeoPandas**](https://geopandas.org/) is a Python package that extends the datatypes used by pandas to allow spatial operations on geometric types.\n",
    "\n",
    "[**OSMnx**](https://osmnx.readthedocs.io/) is a Python package that lets you download geospatial data from OpenStreetMap and model, project, visualize, and analyze real-world street networks and any other geospatial geometries. You can download and model walkable, drivable, or bikeable urban networks with a single line of Python code then easily analyze and visualize them. You can just as easily download and work with other infrastructure types, amenities/points of interest, building footprints, elevation data, street bearings/orientations, and speed/travel time.\n",
    "\n",
    "[**NetworkX**](https://networkx.org/) is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.\n",
    "\n",
    "[**Matplotlib**](https://matplotlib.org/) is a comprehensive Python package for creating static, animated, and interactive visualizations in Python. Matplotlib makes easy things easy and hard things possible.\n",
    "\n",
    "[**Geocube**](https://corteva.github.io/geocube) is a Python package to convert geopandas vector data into rasterized data.\n",
    "\n",
    "[**xarray**](https://docs.xarray.dev/) is a Python package that allows for easy and efficient use of multi-dimensional arrays.\n",
    "\n",
    "Import the packages in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d683ee-d2b5-49a5-9b31-9ab50039f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cdsapi\n",
    "import shapely \n",
    "import matplotlib\n",
    "import urllib3\n",
    "import pyproj\n",
    "import contextily as cx\n",
    "\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "\n",
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3208479-d07e-4d6d-afd7-a9944b9630c0",
   "metadata": {},
   "source": [
    "Import error? Not all of the packages were installed already. Make sure to install the missing packages using pip install in the cell below and then run the cell above again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395181b-53d5-48de-84ff-55e27da494a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "981898d2-5f8f-4990-a236-b1cfe2c7008e",
   "metadata": {},
   "source": [
    "## 2. Downloading and accessing natural hazard data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7693fcc-a0cf-4ed4-a0d0-e3a00b917547",
   "metadata": {},
   "source": [
    "We will first download and explore windstorm and flood data for the Netherlands. \n",
    "\n",
    "### Windstorm Data\n",
    "<hr>\n",
    "\n",
    "The windstorm data will be downloaded from the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu/). As we have seen during the lecture, and as you can also see by browsing on this website, there is an awful lot of climate data available through this Data Store. As such, it is very valuable to understand how to access and download this information to use within an analysis. To keep things simple, we only download one dataset today: [A winter windstorm](https://cds.climate.copernicus.eu/cdsapp#!/dataset/sis-european-wind-storm-indicators?tab=overview). \n",
    "\n",
    "We will do so using an **API**, which is the acronym for application programming interface. It is a software intermediary that allows two applications to talk to each other. APIs are an accessible way to extract and share data within and across organizations. APIs are all around us. Every time you use a rideshare app, send a mobile payment, or change the thermostat temperature from your phone, youâ€™re using an API.\n",
    "\n",
    "However, before we can access this **API**, we need to take a few steps. Most importantly, we need to register ourselves on the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu/) portal. To do so, we need to register, as explained in the video clip below:\n",
    "\n",
    "<img src=\"https://github.com/ElcoK/BigData_AED/blob/main/_static/images/CDS_registration.gif?raw=1\" class=\"bg-primary mb-1\">\n",
    "<br>\n",
    "\n",
    "Now, the next step is to access the API. You can now login on the website of the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu/). After you login, you can click on your name in the top right corner of the webpage (next to the login button). On the personal page that has just opened, you will find your user ID (**uid**) and your personal **API**. You need to add those in the cell below to be able to download the windstorm.\n",
    "\n",
    "As you can see in the cell below, we download a specific windstorm that has occured on the 28th of October in 2013. This is storm [Carmen (also called St Jude)](https://en.wikipedia.org/wiki/St._Jude_storm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4736833f-c0ec-48f4-8c29-1721ba2ecb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = XXX\n",
    "apikey = 'XXX'\n",
    "\n",
    "c = cdsapi.Client(key=f\"{uid}:{apikey}\", url=\"https://cds.climate.copernicus.eu/api/v2\")\n",
    "\n",
    "c.retrieve(\n",
    "    'sis-european-wind-storm-indicators',\n",
    "    {\n",
    "        'variable': 'all',\n",
    "        'format': 'zip',\n",
    "        'product': 'windstorm_footprints',\n",
    "        'year': '2013',\n",
    "        'month': '10',\n",
    "        'day': '28',\n",
    "    },\n",
    "    'Carmen.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec192f1-8ac1-4e61-ac8f-c01d496e157f",
   "metadata": {},
   "source": [
    "### Flood Data\n",
    "<hr>\n",
    "\n",
    "The flood data we will extract from a repository maintained by the European Commission Joint Research Centre. We will download river flood hazard maps from their [Flood Data Collection](https://data.jrc.ec.europa.eu/dataset/1d128b6c-a4ee-4858-9e34-6210707f3c81). \n",
    "\n",
    "Here we do not need to use an API and we also do not need to register ourselves, so we can download any of the files directly. To do so, we use the `urllib` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f3b19-cba4-4f4a-a902-082e396b7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the link to the 1/100 flood map for Europe\n",
    "zipurl = 'https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/FLOODS/EuropeanMaps/floodMap_RP100.zip'\n",
    "\n",
    "# and now we open and extract the data\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8baa489-3b9c-4d16-afdf-359651d2f6ba",
   "metadata": {},
   "source": [
    "The download and zip in the cell above sometimes does not work. If that is indeed the case (e.g., when it seems to remain stuck), download the files manually through the link and upload them in the data folder for this week (as explained at the start of this tutorial.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb3103-bc54-4670-9936-f299561190f6",
   "metadata": {},
   "source": [
    "### Set location to explore\n",
    "---\n",
    "Before we continue, we need to specify our location of interest. This should be a province that will have some flooding and relative high wind speeds occuring (else we will find zero damage). We specify the region of interest in the cell below by using the `geocode_to_gdf()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb7b64e-de75-4490-ac72-bad321d4da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name = \"Gelderland, The Netherlands\" ### But you could also consider Zeeland, for example.\n",
    "area = ox.geocode_to_gdf(place_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd3821f-16dd-4e7b-8ac6-a46475704afd",
   "metadata": {},
   "source": [
    "## 3. Exploring the natural hazard data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e203b2-e4c0-458a-a91e-9218614baeab",
   "metadata": {},
   "source": [
    "Now we will explore our natural hazard data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d77ba-32df-44c4-a565-b197b7e4cefc",
   "metadata": {},
   "source": [
    "### Windstorm Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b379bcc-84a2-4bb6-86a6-d0e3ad0d1c84",
   "metadata": {},
   "source": [
    "As you can see in the section above, we have downloaded the storm footprint in a zipfile. Let's open the zipfile and load the dataset using the `xarray` package through the `open_dataset()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d33537-8db8-4def-89ee-2387ec993831",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('Carmen.zip') as zf:\n",
    "    \n",
    "    # Let's get the filename first\n",
    "    file = zf.namelist()[0]\n",
    "    \n",
    "    # And now we can open and select the file within Python\n",
    "    with zf.open(file) as f:\n",
    "        windstorm_europe = xr.open_dataset(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375410e2-ebe5-4f4d-b924-ad15e8fb9d59",
   "metadata": {},
   "source": [
    "Let's have a look at the storm we have downloaded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35bb91-0705-4d80-b063-adabc74cc353",
   "metadata": {},
   "outputs": [],
   "source": [
    "windstorm_europe['FX'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092e7f97-cf7a-4000-818f-1a73e578b0ec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 1:</b> Describe windstorm Carmen. When did this event happen, which areas were most affected? Can you say something about the maximum wind speeds in different areas, based on the plot? And what does FX mean?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e8caf3-c5c3-4970-b923-b58d1fe007f8",
   "metadata": {},
   "source": [
    "Unfortunately, our data does not have a proper coordinate system defined yet. As such, we will need to use the `rio.write_crs()` function to set the coordinate system to **EPSG:4326** (the standard global coordinate reference system). \n",
    "\n",
    "We also need to make sure that the functions will know what the exact parameters are that we have to use for our spatial dimenions (e.g. longitude and latitude). It prefers to be named `x` and `y`. So we use the `rename()` function before we use the `set_spatial_dims()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7b6ec-a394-4e3c-82dd-8a59ce029563",
   "metadata": {},
   "outputs": [],
   "source": [
    "windstorm_europe.rio.write_crs(4326, inplace=True)\n",
    "windstorm_europe = windstorm_europe.rename({'Latitude': 'y','Longitude': 'x'})\n",
    "windstorm_europe.rio.set_spatial_dims(x_dim=\"x\",y_dim=\"y\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e41966-7273-4521-9b27-4c9498a66e0b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 2:</b> Climate data is often stored as a netCDF file. Please describe what a netCDF file is. Which information is stored in the netCDF file we have downloaded for the windstorm? What type of metadata does it contain?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba5e684-f658-42e9-bded-bbb47ced24e4",
   "metadata": {},
   "source": [
    "Following, we also make sure it will be in the European coordinate system **EPSG:3035** to ensure we can easily use it together with the other data. To do so, we use the `rio.reproject()` function. You can simple add the number of the coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b276083-7825-4576-832b-129566f65222",
   "metadata": {},
   "outputs": [],
   "source": [
    "windstorm_europe = windstorm_europe. [add function]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0650103f-eed7-43f6-b9ef-a221781e356a",
   "metadata": {},
   "source": [
    "Now we have all the information to clip the windstorm data to our area of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbfe52-1484-48fd-9dee-fc6064fe343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "windstorm_map = windstorm_europe.rio.clip(area.envelope.values, area.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c142f-2741-41bf-bace-96b6fede47f2",
   "metadata": {},
   "source": [
    "And let's have a look as well by using the `plot()` function. Please note that the legend is in meters per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b8e8ca-6a58-44df-8981-b040cc55b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "windstorm_map['FX']. [add function]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bded755-8d9b-41a0-bd6e-a25000bc7486",
   "metadata": {},
   "source": [
    "### Flood Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef96754-17bc-4d02-92ab-bb06280015a5",
   "metadata": {},
   "source": [
    "And similarly, we want to open the flood map. But now we do not have to unzip the file anymore and we can directly open it through using `xarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78db556-c66c-46a0-9615-b98e26b9e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_map_path = 'floodmap_EFAS_RP100_C.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555fab92-0c74-426e-bcfe-655cf6b25682",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_map = xr.open_dataset(flood_map_path, engine=\"rasterio\")\n",
    "flood_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb3c24d-4ed2-4717-befc-67e52e1bbbea",
   "metadata": {},
   "source": [
    "And let's make sure we set all the variables and the CRS correctly again to be able to open the data properly. Note that we should now use **EPSG:3035**. This is the standard coordinate system for Europe, in meters (instead of degrees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6de85-b165-4b7e-85ea-d09fe6bf9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_map.rio.write_crs(      , inplace=True)\n",
    "flood_map.rio.set_spatial_dims(x_dim=\"x\",y_dim=\"y\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebad344-dd4b-4c37-bafe-2464f11a79b2",
   "metadata": {},
   "source": [
    "Now it is pretty difficult to explore the data for our area of interest, so let's clip the flood data.  \n",
    "\n",
    "We want to clip our flood data to our chosen area. The code, however, is very inefficient and will run into memories issues on Google Colab. As such, we first need to clip it by using a bounding box, followed by the actual clip.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 4:</b> Please provide the lines of code below in which you show how you have clipped the flood map to your area.\n",
    "</div>\n",
    "\n",
    "*A few hints*:\n",
    "\n",
    "* carefully read the documentation of the `.clip_box()` function of rioxarray. Which information do you need? \n",
    "* is the GeoDataFrame of your region (the area GeoDataframe) in the same coordinate system? Perhaps you need to convert it using the `.to_crs()` function. \n",
    "* how do you get the bounds from your area GeoDataFrame? \n",
    "* The final step of the clip would be to use the `.rio.clip()` function, using the actual area file and the flood map clipped to the bounding box. Please note that you should **not** use the envelope here, like we did in the previous clip. Here we really want to use the exact geometry values.\n",
    "\n",
    "As you will see, we first clip it very efficiently using the bounding box. After that, we do an exact clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a22299-6507-45b3-b4ef-1321a193ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lon =  area.to_crs(epsg=3035).bounds.minx.values[0]\n",
    "min_lat = area.to_crs(epsg=3035).bounds.miny\n",
    "max_lon =  area.to_crs(epsg=3035).bounds\n",
    "max_lat =  area.to_crs(epsg=3035).\n",
    "\n",
    "flood_map_area = flood_map.rio.clip_box(minx=.... )\n",
    "flood_map_area = flood_map_area.rio.clip(area.XXXX.values, area.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744f4ff-e7c2-4b1b-b366-9ebd577f76bd",
   "metadata": {},
   "source": [
    "And let's have a look as well. Please note that the legend is in meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f23727-c8c0-4379-95f7-bc41ba5b3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_map_area['band_data'].plot(cmap='Blues',vmax=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c98ee1-d8f8-4eba-bfd2-36f26e849279",
   "metadata": {},
   "source": [
    "## 4. Downloading and exploring Land Cover data and Land Use data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0402ee8-6460-4db0-b216-b16b88ff2c56",
   "metadata": {},
   "source": [
    "We will explore rasterized Corine Land Cover data and land use data retrieved from OpenStreetMap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccebb6a-8c7b-4c7f-b974-899e15c9631b",
   "metadata": {},
   "source": [
    "### Download and access Copernicus Land Cover data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672472d8-aff1-498f-ac36-41082ac32c4e",
   "metadata": {},
   "source": [
    "Unfortunately, there is no API option to download the [Corine Land Cover](https://land.copernicus.eu/pan-european/corine-land-cover) data. We will have to download the data from the website first.\n",
    "\n",
    "To do so, we will first have to register ourselves again on the website. Please find in the video clip below how to register yourself on the website of the [Copernicus Land Monitoring Service](https://land.copernicus.eu/):\n",
    "\n",
    "<img src=\"https://github.com/ElcoK/BigData_AED/blob/main/_static/images/CLMS_registration.gif?raw=1\" class=\"bg-primary mb-1\">\n",
    "\n",
    "Now click on the Login button in the top right corner to login on the website. There are many interesting datasets on this website, but we just want to download the Corine Land Cover data, and specifically the latest version: [Corine Land Cover 2018](https://land.copernicus.eu/pan-european/corine-land-cover/clc2018?tab=download). To do so, please select the **Corine Land Cover - 100 meter**. Now click on the large green Download button. Your download should start any minute.\n",
    "\n",
    "Slightly annoying, the file you have downloaded is double zipped. Its slightly inconvenient to open this through Python and within Google Drive. So let's unzip it twice outside of Python (on your local machine) and then direct yourself to the `DATA` directory within the unzipped file. Here you can find a file called `U2018_CLC2018_V2020_20u1.tif`. Drop this file into this week's data directory, as specified at the start of this tutorial when we mounted our Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c9079-cde0-4be2-8b72-f7403d5f0e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLC_location = 'U2018_CLC2018_V2020_20u1.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa699e-1ba0-4ed8-9996-38d8cc81578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLC = xr.open_dataset(CLC_location, engine=\"rasterio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d263e20d-d88b-4cf3-ad5c-c1ff2d93ad6b",
   "metadata": {},
   "source": [
    "Similarly to the flood map data, we need to do a two-stage clip again (like we did before in this tutorial to ensure we get only our area of interest without exceeding our RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299869a-2724-44c6-b5af-d134f7b9aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLC_region = CLC.rio.clip_box(\n",
    "CLC_region = CLC_region.rio.clip("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706a9da-4336-4f06-a8a7-4c825639dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLC_region = CLC_region.rename({'x': 'lat','y': 'lon'})\n",
    "CLC_region.rio.set_spatial_dims(x_dim=\"lat\",y_dim=\"lon\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31c0989-e96e-4809-a24d-13ab00de751f",
   "metadata": {},
   "source": [
    "And now we create a *color_dict*, to ensure we can visualize the data properly. We use the colorscheme of Corine Land Cover. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198958ec-68a5-44d2-9b8c-91a2dd19484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLC_values = [111, 112, 121, 122, 123, 124, 131, 132, 133, 141, 142, 211, 212, 213, 221, 222, 223, 231, 241, 242,\n",
    " 243, 244, 311, 312, 313, 321, 322, 323, 324, 331, 332, 333, 334, 335, 411, 412, 421, 422, 423, 511, 512, 521, 522, 523]\n",
    "\n",
    "CLC_colors = ['#E6004D', '#FF0000', '#CC4DF2', '#CC0000', '#E6CCCC', '#E6CCE6', '#A600CC', '#A64DCC', '#FF4DFF', '#FFA6FF', '#FFE6FF', '#FFFFA8', '#FFFF00', '#E6E600',\n",
    " '#E68000', '#F2A64D', '#E6A600', '#E6E64D', '#FFE6A6', '#FFE64D', '#E6CC4D', '#F2CCA6', '#80FF00', '#00A600',\n",
    " '#4DFF00', '#CCF24D', '#A6FF80', '#A6E64D', '#A6F200', '#E6E6E6', '#CCCCCC', '#CCFFCC', '#000000', '#A6E6CC',\n",
    " '#A6A6FF', '#4D4DFF', '#CCCCFF', '#E6E6FF', '#A6A6E6', '#00CCF2', '#80F2E6', '#00FFA6', '#A6FFE6', '#E6F2FF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c9c52",
   "metadata": {},
   "source": [
    "The code below allows us the use the color_dict above to plot the CLC map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b50772-57d5-4e49-a600-00bfeaf9ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict_raster = dict(zip(CLC_values,CLC_colors))\n",
    "\n",
    "# We create a colormar from our list of colors\n",
    "cm = ListedColormap(CLC_colors)\n",
    "\n",
    "# Let's also define the description of each category : 1 (blue) is Sea; 2 (red) is burnt, etc... Order should be respected here ! Or using another dict maybe could help.\n",
    "labels = np.array(CLC_values)\n",
    "len_lab = len(labels)\n",
    "\n",
    "# prepare normalizer\n",
    "## Prepare bins for the normalizer\n",
    "norm_bins = np.sort([*color_dict_raster.keys()]) + 0.5\n",
    "norm_bins = np.insert(norm_bins, 0, np.min(norm_bins) - 1.0)\n",
    "\n",
    "## Make normalizer and formatter\n",
    "norm = matplotlib.colors.BoundaryNorm(norm_bins, len_lab, clip=True)\n",
    "fmt = matplotlib.ticker.FuncFormatter(lambda x, pos: labels[norm(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68baa525-98be-4069-8129-dc6c22db4793",
   "metadata": {},
   "source": [
    "And let's plot the Corine Land Cover data for our area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a977453-9180-4de6-872e-1fe7818f2915",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(14,10))\n",
    "\n",
    "CLC_region[\"band_data\"].plot(ax=ax,levels=len(CLC_colors),colors=CLC_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465c4b28-3d01-4960-bb7c-8709a0c023bc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 5:</b> Describe the different land-use classes within your region that you see on the Corine Land Cover map. Do you see any dominant land-use classes? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8867d41e-2b7b-40c2-8576-611f2c04f547",
   "metadata": {},
   "source": [
    "### Extract and visualize land-use information from OpenStreetMap\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0dd8ab-15e8-494d-a6fb-3861636e5ed4",
   "metadata": {},
   "source": [
    "The next step is to define which area you want to focus on. In the cell below, you will now read \"Kampen, The Netherlands\". Change this to any area or municipality in the Netherlands that (1) you can think of and (2) will work. \n",
    "\n",
    "In some cases, the function does not recognize the location. You could either try a different phrasing or try a different location. Many parts of the Netherlands should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12189f0d-5f9f-4ada-922a-6fc12f9bbf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name = \"Kampen, The Netherlands\"\n",
    "area = ox.geocode_to_gdf(place_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2077d677-c8c2-4fd5-b0d0-21fad4f3eec5",
   "metadata": {},
   "source": [
    "Now let us visualize the bounding box of the area. As you will notice, we also estimate the size of the area. If the area size is above 50km2, or when you have many elements within your area (for example the amsterdam city centre), extracting the data from OpenStreetMap may take a little while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50447dc3-9d91-4a64-adea-90cbb0e0a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_to_check = area.to_crs(epsg=3857)\n",
    "ax = area_to_check.plot(figsize=(10, 10), color=\"none\", edgecolor=\"k\", linewidth=4)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_axis_off()\n",
    "cx.add_basemap(ax, zoom=11)\n",
    "\n",
    "size = int(area_to_check.area/1e6)\n",
    "\n",
    "ax.set_title(\"{}. Total area: {} km2\".format(place_name,size),fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154abf9-c923-4253-9e97-e8c91fe9d632",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 1:</b> To make sure we understand which area you focus on, please submit the figure that outlines your area.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b5084-08f0-471d-8982-06b340e5d3f5",
   "metadata": {},
   "source": [
    "Now we are satisfied with the selected area, we are going to extract the land-use information from OpenStreetMap. To find the right information from OpenStreetMap, we use **tags**.\n",
    "\n",
    "As you will see in the cell below, we use the tags *\"landuse\"* and *\"natural\"*. We need to use the *\"natural\"* tag to ensure we also obtain water bodies and other natural elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f52137d-bf2c-4405-9df1-42ac73a5d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {'landuse': True, 'natural': True}   \n",
    "landuse = ox.features_from_place(place_name, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f44095d-c47c-49d4-ac8d-6a91eae8f1ae",
   "metadata": {},
   "source": [
    "In case the above does not work, you can continue the assignment by using the code below (make sure you remove the hashtags to run it). If you decide to use the data as specified below, also change the map at the start to 'Kampen'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd17e2-d990-447a-b3d4-75dbe2b93ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote_url = 'https://github.com/ElcoK/BigData_AED/raw/main/week5/kampen_landuse.gpkg'\n",
    "# file = 'kampen_landuse.gpkg'\n",
    "\n",
    "# request.urlretrieve(remote_url, file)\n",
    "#landuse = gpd.GeoDataFrame.from_file('kampen_landuse.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9e972-55b9-45a9-b727-45066032e900",
   "metadata": {},
   "source": [
    "To ensure we really only get the area that we want, we use geopandas's `clip` function to only keep the area we want. This function does exactly the same as the `clip` function in QGIS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be7294-2cc6-4997-9c62-a5aea3fd1c29",
   "metadata": {},
   "source": [
    "When we want to visualize or analyse the data, we want all information in a single column. However, at the moment, all information that was tagged as *\"natural\"*, has no information stored in the *\"landuse\"* tags. It is, however, very convenient if we can just use a single column for further exploration of the data. \n",
    "\n",
    "To overcome this issue, we need to add the missing information to the landuse column, as done below. Let's first have a look which categories we have in the **natural** column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed6e32f-06a7-4189-8e77-efd1a9cf77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse.natural.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6a6af-c3db-450b-944c-95c7cef1fd32",
   "metadata": {},
   "source": [
    "And now we can add them to the **landuse** column. We made a start, but its up to you to fill in the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b14f7a-f62d-4575-ad02-39f279fde5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse.loc[landuse.natural=='water','landuse'] = 'water'\n",
    "landuse.loc[landuse.natural=='wetland','landuse'] = 'wetlands'\n",
    "\n",
    "\n",
    "landuse = landuse.dropna(subset=['landuse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851df40d-02d1-4409-9a89-9d1edcfa6bcd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 2:</b> Please provide in the answer box in Canvas the code that you used to make sure that all land uses are now registered within the landuse column.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead9126-edc3-41f1-80de-339e1e42dbda",
   "metadata": {},
   "source": [
    "Our next step is to prepare the visualisation of a map. What better way to explore land-use information than plotting it on a map? \n",
    "\n",
    "As you will see below, we can create a dictionary with color codes that will color each land-use class based on the color code provided in this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64197848-0d42-480e-9d7f-4a68bff63772",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {  \"grass\":'#c3eead',               \"railway\": \"#000000\",\n",
    "                \"forest\":'#1c7426',              \"orchard\":'#fe6729',\n",
    "                \"residential\":'#f13013',         \"industrial\":'#0f045c',\n",
    "                \"retail\":'#b71456',              \"education\":'#d61181',              \n",
    "                \"commercial\":'#981cb8',          \"farmland\":'#fcfcb9',\n",
    "                \"cemetery\":'#c39797',            \"construction\":'#c0c0c0',\n",
    "                \"meadow\":'#c3eead',              \"farmyard\":'#fcfcb9',\n",
    "                \"plant_nursery\":'#eaffe2',       \"scrub\":'#98574d',\n",
    "                \"allotments\":'#fbffe2',          \"reservoir\":'#8af4f2',\n",
    "                \"static_caravan\":'#ff3a55',      \"wetlands\": \"#c9f5e5\",\n",
    "                \"water\": \"#c9e5f5\",              \"beach\": \"#ffeead\",\n",
    "                \"landfill\" : \"#B08C4D\",          \"recreation_ground\" : \"#c3eead\",\n",
    "                \"brownfield\" : \"#B08C4D\",        \"village_green\" : \"#f13013\" ,\n",
    "                \"military\": \"#52514E\",            \"garden\" : '#c3eead'\n",
    "             } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408cdac8-2ca1-4eef-8997-8c83b852f5c5",
   "metadata": {},
   "source": [
    "Unfortunately, OpenSteetMap very often contains elements that have a unique tag. As such, it may be the case that some of our land-use categories are not in the dictionary yet. \n",
    "\n",
    "Let's first create an overview of the unique land-use categories within our data through using the `.unique()` function within our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c41069-fb2c-4606-adcc-e73ab95778ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse.landuse.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f354fe05-b608-435f-acf4-6310886071dd",
   "metadata": {},
   "source": [
    "Ofcourse we can visually compare the array above with our color_dict, but it is much quicker to use `Sets` to check if there is anything missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba31d28-3398-4d33-a325-eab786869020",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(landuse.landuse.unique())-set(color_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2de6c7-180e-43b3-ab32-ee7df7ff6ea2",
   "metadata": {},
   "source": [
    "In case anything is missing, add them to the color_dict dictionairy and re-run that cell. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 3:</b> Show us in Canvas (i) which land-use categories you had to add, and (ii) how your final color dictionary looks like.\n",
    "</div>\n",
    "\n",
    "```{tip}\n",
    "You can easily find hexcodes online to find the right colour for each land-use category. Just google hexcodes!\n",
    "```\n",
    "\n",
    "\n",
    "Our next step is to make sure that we can connect our color codes to our dataframe with land-use categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45093fa0-b95b-49e1-bb32-d149ba424931",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {key: color_dict[key]\n",
    "             for key in color_dict if key not in  list(set(color_dict)-set(landuse.landuse.unique()))}\n",
    "\n",
    "map_dict = dict(zip(color_dict.keys(),[x for x in range(len(color_dict))]))\n",
    "\n",
    "landuse['col_landuse'] = landuse.landuse.apply(lambda x: color_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010bec6f-fd76-40d2-a38c-be266e57d056",
   "metadata": {},
   "source": [
    "Now we can plot the figure!\n",
    "\n",
    "As you will see in the cell below, we first state that we want to create a figure with a specific figure size. You can change the dimensions to your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f01254-e1d7-4e3f-b40c-b2358223670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(12,10))\n",
    "\n",
    "# add color scheme\n",
    "color_scheme_map = list(color_dict.values())\n",
    "cmap = LinearSegmentedColormap.from_list(name='landuse',\n",
    "                                     colors=color_scheme_map)  \n",
    "\n",
    "# and plot the land-use map.\n",
    "landuse.plot(color=landuse['col_landuse'],ax=ax,linewidth=0)\n",
    "\n",
    "# remove the ax labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_axis_off()\n",
    "\n",
    "# add a legend:\n",
    "legend_elements = []\n",
    "for iter_,item in enumerate(color_dict):\n",
    "    legend_elements.append(Patch(facecolor=color_scheme_map[iter_],label=item))        \n",
    "\n",
    "ax.legend(handles=legend_elements,edgecolor='black',facecolor='#fefdfd',prop={'size':12},loc=(1.02,0.2)) \n",
    "\n",
    "# add a title\n",
    "ax.set_title(place_name,fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ca96a-2ec2-4889-b30b-1f9d23cc0d18",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 4:</b> Please upload a figure of your land-use map, using OpenStreetMap. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99777639-4201-42aa-ab97-1705bed60392",
   "metadata": {},
   "source": [
    "### Rasterize land-use information\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8bda0f-aea9-471c-af15-31d9bf2bd191",
   "metadata": {},
   "source": [
    "As you have noticed already during the lecture, and as we have seen during TAA1 with the Google Earth Engine, most land-use data is in raster format. \n",
    "\n",
    "In OpenStreetMap everything is stored in vector format. As such, the land-use information we extracted from OpenStreetMap is also in vector format. While it is not always necessary to have this information in raster format, it is useful to know how to convert your data into a raster format.\n",
    "\n",
    "To do so, we can make use of the **GeoCube** package, which is a recently developed Python package that can very easily convert vector data into a raster format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d84eb30-2657-4cd3-8300-be6e22673d11",
   "metadata": {},
   "source": [
    "The first thing we will need to do is to define all the unique land-use classes and store them in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d1662b-23a0-443d-8465-0acad5e374c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_enums = {'landuse': landuse.landuse.drop_duplicates().values.tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17845c5f-ec24-498c-a185-1cbf5d4054dd",
   "metadata": {},
   "source": [
    "And now we simply use the `make_geocube()` function to convert our vector data into raster data. \n",
    "\n",
    "In the `make_geocube()` function, we have to specify several arguments:\n",
    "\n",
    "- Through the `vector_data` argument we have to state which dataframe we want to rasterize.\n",
    "- Through the `output_crs` argument we have to state the coordinate reference system (CRS). We use the OpenStreetMap default EPSG:4326.\n",
    "- Through the `resolution` argument we have to state the resolution. In our case, we will have to set this in degrees. 0.01 degrees is equivalent to roughly 10km around the equator. \n",
    "- Through the `categorical_enums` argument we specify the different land-use categories.\n",
    "\n",
    "Play around with the different resolutions to find the level of detail. The higher the resolution (i.e., the more zeros behind the comma), the longer it will take to rasterize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca109c1-5169-4833-818d-bae97f0b33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse_grid = make_geocube(\n",
    "    vector_data=,\n",
    "    output_crs=,\n",
    "    resolution=(-XXXX, XXXX),\n",
    "    categorical_enums=categorical_enums\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ea735-0255-4b44-ab66-210bf3655213",
   "metadata": {},
   "source": [
    "Let's explore what this function has given us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca50588-074b-4217-a384-f582a57f6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse_grid[\"landuse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35204590-9e19-45a0-8065-4e453d024d69",
   "metadata": {},
   "source": [
    "The output above is a typical output of the **xarray** package. \n",
    "\n",
    "- The `array` shows the numpy array with the actual values. As you can see, the rasterization process has used the value `-1` for NoData. \n",
    "- The `Coordinates` table shows the x (longitude) and y (latitude) coordinates of the array. It has the exact same size as the `array` with land-use values.\n",
    "- The `Attributes` table specifies the NoData value (the `_FillValue` element, which indeed shows `-1`) and the name of the dataset.\n",
    "\n",
    "Now let's plot the data to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f75e9-4747-43e1-93a0-d1b63d90378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(14,10))\n",
    "\n",
    "landuse_grid[\"landuse\"].plot(ax=ax,vmin=0,vmax=15,levels=15,cmap='tab20')\n",
    "\n",
    "# remove the ax labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_axis_off()\n",
    "\n",
    "#add a title\n",
    "\n",
    "ax.set_title('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b1ce7-f6e6-410d-be82-e24e9d224bd3",
   "metadata": {},
   "source": [
    "As we can see in the figure above, the land-use categories have turned into numbers, instead of land-use categories described by a string value. \n",
    "\n",
    "This is of course a lot harder to interpret. Let's re-do some parts to make sure we can properly link them back to the original data.\n",
    "\n",
    "To do so, we will first need to make sure that we know which values (numbers) are connected to each land-use category. Instead of trying to match, let's predefine this ourselves!\n",
    "\n",
    "We will start with creating a dictionary that allows us to couple a number to each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882f6c1-9008-4815-b19f-7ec2771aaa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dict = dict(zip(landuse.landuse.unique(),np.arange(0,len(landuse.landuse.unique()),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b572e0-d97b-47cb-8fa7-1a2c11afc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dict['nodata'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4797d-9d48-4c83-a564-936d579dc256",
   "metadata": {},
   "source": [
    "And we now use this dictionary to add a new column to the dataframe with the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b7dd2-84df-428c-9c70-7d07aa745346",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse_valued = make_geocube(\n",
    "    vector_data=XXXX,\n",
    "    output_crs=XXXX,\n",
    "    resolution=(-XXXX, XXXX),\n",
    "    categorical_enums={'landuse_value': landuse.landuse_value.drop_duplicates().values.tolist()\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510409be-3b7f-4f75-848b-4146bee15338",
   "metadata": {},
   "source": [
    "And let's use the original `color_dict` dictionary to find the right hex codes for each of the land-use categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458b393b-47e8-44a3-bebc-148b4d764401",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = landuse.landuse.drop_duplicates().values.tolist()\n",
    "colormap_raster = [color_dict[lu_class] for lu_class in unique_classes] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8197f4b9-9c0f-4999-89f3-1ea657888193",
   "metadata": {},
   "source": [
    "To plot the new result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb9d2c-2435-485f-8daa-6c54e29e8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(14,10))\n",
    "\n",
    "landuse_valued[\"landuse_value\"].plot(ax=ax,vmin=0,vmax=19,levels=len(unique_classes),colors=colormap_raster)\n",
    "\n",
    "# remove the ax labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_axis_off()\n",
    "\n",
    "# add title\n",
    "ax.set_title('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e42dd3a-c0c3-496f-bbc4-dbdf1f3901d1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 5:</b> In the rasterization process, we use the `.make_geocube()` function. Please elaborate on the following: i)why is it important to specify the right coordinate system? What could happen if you choose the wrong coordinate system? ii) which resolution did you choose and why? iii)Why did the first result did not give us the right output with the correct colors? How did you solve this? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8789a06-d041-4d6f-aab7-48032ac8c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = landuse.landuse.drop_duplicates().values.tolist()\n",
    "colormap_raster = [color_dict[lu_class] for lu_class in unique_classes] \n",
    "color_dict_raster = dict(zip(np.arange(-1,len(landuse.landuse.unique())+1,1),['#ffffff']+colormap_raster))\n",
    "\n",
    "# We create a colormar from our list of colors\n",
    "cm = ListedColormap([color_dict_raster[x] for x in color_dict_raster.keys()])\n",
    "\n",
    "# Let's also define the description of each category. Order should be respected here!\n",
    "labels = np.array(['nodata'] + unique_classes)\n",
    "len_lab = len(labels)\n",
    "\n",
    "# prepare normalizer\n",
    "## Prepare bins for the normalizer\n",
    "norm_bins = np.sort([*color_dict_raster.keys()]) + 0.5\n",
    "norm_bins = np.insert(norm_bins, 0, np.min(norm_bins) - 1.0)\n",
    "\n",
    "## Make normalizer and formatter\n",
    "norm = matplotlib.colors.BoundaryNorm(norm_bins, len_lab, clip=True)\n",
    "fmt = matplotlib.ticker.FuncFormatter(lambda x, pos: labels[norm(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36beb42-1da5-4da0-bb02-b61604b0852f",
   "metadata": {},
   "source": [
    "Let's plot the map again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def51260-e57c-4957-8263-2b43a83a134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(14,10))\n",
    "\n",
    "ax = landuse_valued[\"landuse_value\"].plot(levels=len(unique_classes), cmap=cm, norm=norm)\n",
    "\n",
    "# remove the ax labels\n",
    "diff = norm_bins[1:] - norm_bins[:-1]\n",
    "tickz = norm_bins[:-1] + diff / 2\n",
    "cb = fig.colorbar(ax, format=fmt, ticks=tickz)\n",
    "\n",
    "# set title again\n",
    "fig.axes[0].set_title('')\n",
    "\n",
    "fig.axes[0].set_xticks([])\n",
    "fig.axes[0].set_yticks([])\n",
    "fig.axes[0].set_axis_off()\n",
    "\n",
    "# for some weird reason we get two colorbars, so we remove one:\n",
    "fig.delaxes(fig.axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a2267-4057-485c-85f1-1929896ad9ee",
   "metadata": {},
   "source": [
    "## 5. Perform a raster-based damage assessment using OSM and Corine Land Cover\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965589e-5317-4111-a9ad-06094f76569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! @TASK: Copy paste from Tutorial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c4ad75-a555-414d-bb64-6af5f10a2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! @TASK: Let students also perform risk assessment based on rasterized OSM land use data?? Code needs to be written for that. Or think about a really good question that we can ask here about this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac963e-2f8a-4e84-a313-96c3d00f2b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d46699-d759-48e3-a5ef-09d45ec8e41a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c9da2-4257-4749-9fbf-fe0f94ef61a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28e483d0-06b1-432f-86e6-d7a68e9811a4",
   "metadata": {},
   "source": [
    "## 6. Extracting high-resolution data from OpenStreetMap\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b596d-ad9f-4e42-bc2f-e889d216f0e7",
   "metadata": {},
   "source": [
    "### Extracting buildings from OpenStreetMap\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f86ddc-ce27-4753-9e70-af6df03d7850",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\"building\": True}\n",
    "buildings = ox.features_from_place(place_name, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae51a7-1c32-4d96-bff0-cb67ce796fc8",
   "metadata": {},
   "source": [
    "There is a lot more data to extract from OpenStreetMap besides land-use information. Let's extract some building data. To do so, we use the *\"building\"* tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a60806-c927-4d0c-ab04-dc07c9c7a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f8340c-21e7-4e9b-996d-e2234ced09d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! @TASK: copy-paste cells from tutorial 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a6ba47-e148-48e1-a0a2-e7e2c75c4257",
   "metadata": {},
   "source": [
    "### Analyze and visualize building stock\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75442fe8-0e84-4315-a591-3c705d280357",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(5,18))\n",
    "\n",
    "building_year.plot(kind='barh',ax=ax)\n",
    "\n",
    "ax.tick_params(axis='y', which='major', labelsize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5051e-797f-4a42-8680-cd9767086d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "! @TASK: copy-paste cells from tutorial 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59fa9dc-68f1-4d39-8adc-f917a0af3a04",
   "metadata": {},
   "source": [
    "### Extracting roads from OpenStreetMap\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34bcba3-d295-49d8-9948-054723c2e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! @TASK: copy-paste cells from tutorial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b68047e-2370-4584-b6fb-d97013ce2e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "508022f5-46d7-4c69-91d2-46711d6a514c",
   "metadata": {},
   "source": [
    "## 7. Perform a damage assessment of the road network using OpenStreetMap\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be31e8c-34d3-42c7-a4bd-76d681702f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "! @TASK: copy-paste cells from tutorial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1693da4-89a6-449d-bc3c-2ae39fd998d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06b72a1d-12cf-4fef-bfc7-fc95d8618bb7",
   "metadata": {},
   "source": [
    "### 6. Windstorm Damage\n",
    "\n",
    "---\n",
    "To estimate the potential damage of our windstorm, we use the vulnerability curves developed by [Yamin et al. (2014)](https://www.sciencedirect.com/science/article/pii/S2212420914000466). Following [Yamin et al. (2014)](https://www.sciencedirect.com/science/article/pii/S2212420914000466), we will apply a sigmoidal vulnerability function satisfying two constraints: (i) a minimum threshold for the occurrence of damage with an upper bound of 100% direct damage; (ii) a high power-law function for the slope, describing an increase in damage with increasing wind speeds. Due to the limited amount of vulnerability curves available for windstorm damage, we will use the damage curve that represents low-rise *reinforced masonry* buildings for all land-use classes that may contain buildings. Obviously, this is a large oversimplification of the real world, but this should be sufficient for this exercise. When doing a proper stand-alone windstorm risk assessment, one should take more effort in collecting the right vulnerability curves for different building types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7691b461-6bda-463c-a194-0439e12a0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_curves = pd.read_excel(\"https://github.com/ElcoK/BigData_AED/raw/main/week5/damage_curves.xlsx\",sheet_name='wind_curves')\n",
    "maxdam = pd.read_excel(\"https://github.com/ElcoK/BigData_AED/raw/main/week5/damage_curves.xlsx\",sheet_name='maxdam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937ef9a-a0ad-45c5-9bde-56df77527ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse_map = CLC_region_wind['band_data'].to_numpy()[0,:,:]\n",
    "wind_map = windstorm['FX'].to_numpy()[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb9e4c-339a-48ad-858a-38a651428884",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdcb330-72c2-4f78-8ec7-b396da9eb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_map_kmh = wind_map*XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f8fff9-f846-4d3a-9e1b-3a28ae7f72f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_damage_CLC = DamageScanner(landuse_map,wind_map_kmh,wind_curves,maxdam)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05367c3e-d05f-4b6a-a99b-8d9cb4a28fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_damage_CLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9cea94-21fe-4015-a4ec-08c9dd9fd722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ac644de-8684-48ad-85d1-a233133f9753",
   "metadata": {},
   "source": [
    "### Section 3: Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2d2d3-8123-4a19-b1d4-6f8e921e3da1",
   "metadata": {},
   "source": [
    "#### Example 1:  ThE function damage scanner has been used quite extensively in this assignment. Explain in detail the sequantial flow of this functions (Can be added as comments)? CELL SIZE PARAMETER ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36c717-97d9-4df4-8992-0860b9e565a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DamageScanner(landuse_map,inun_map,curve_path,maxdam_path,cellsize=100):\n",
    "        \n",
    "    \n",
    "    landuse = landuse_map.copy()\n",
    "    \n",
    "   \n",
    "    inundation = inun_map.copy()\n",
    "    \n",
    "    inundation = np.nan_to_num(inundation)        \n",
    "\n",
    "    \n",
    "    if isinstance(curve_path, pd.DataFrame):\n",
    "        curves = curve_path.values   \n",
    "    elif isinstance(curve_path, np.ndarray):\n",
    "        curves = curve_path\n",
    "\n",
    "   \n",
    "    if isinstance(maxdam_path, pd.DataFrame):\n",
    "        maxdam = maxdam_path.values \n",
    "    elif isinstance(maxdam_path, np.ndarray):\n",
    "        maxdam = maxdam_path\n",
    "        \n",
    "    \n",
    "    inun = inundation * (inundation>=0) + 0\n",
    "    inun[inun>=curves[:,0].max()] = curves[:,0].max()\n",
    "    waterdepth = inun[inun>0]\n",
    "    landuse = landuse[inun>0]\n",
    "\n",
    "    \n",
    "    numberofclasses = len(maxdam)\n",
    "    alldamage = np.zeros(landuse.shape[0])\n",
    "    damagebin = np.zeros((numberofclasses, 4,))\n",
    "    for i in range(0,numberofclasses):\n",
    "        n = maxdam[i,0]\n",
    "        damagebin[i,0] = n\n",
    "        wd = waterdepth[landuse==n]\n",
    "        alpha = np.interp(wd,((curves[:,0])),curves[:,i+1])\n",
    "        damage = alpha*(maxdam[i,1]*cellsize)\n",
    "        damagebin[i,1] = sum(damage)\n",
    "        damagebin[i,2] = len(wd)\n",
    "        if len(wd) == 0:\n",
    "            damagebin[i,3] = 0\n",
    "        else:\n",
    "            damagebin[i,3] = np.mean(wd)\n",
    "        alldamage[landuse==n] = damage\n",
    "\n",
    "    \n",
    "    loss_df = pd.DataFrame(damagebin.astype(float),columns=['landuse','losses','area','avg_depth']).groupby('landuse').sum()\n",
    "    \n",
    "    \n",
    "    return loss_df.sum().values[0],loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96774ff-3732-42e8-bc33-6c24b2c61479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

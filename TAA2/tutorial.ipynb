{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbd68ab3-f04b-434f-a956-e730535c9ee5",
   "metadata": {},
   "source": [
    "## TAA2: Natural Hazard Risk Assessment using Open Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cc742-23a7-4895-8d2a-7e826d8a23b8",
   "metadata": {},
   "source": [
    "Within this tutorial, we are going to use publicly available hazard data and exposure data to do a risk assessment for the Netherlands. More specifically, we will look at damage due to wind storms and flooding. We will use both Copernicus Land Cover data and OpenStreetMap to estimate the potential damage of natural hazards to the built environment.\n",
    " \n",
    "We will first download, access and explore hazard data retrieved from the Copernicus Climate Data Copernicus Store and the European Commission Joint Research Centre. After this, we will learn how to download and access Copernicus Land Cover data. We will also explore the power of OpenStreetMap that provides vector data. We will learn how to extract information from OpenStreetMap, how you can explore and visualize this. Lastly, we will use Copernicus Land Cover data to estimate the damage to specific land-uses, whereas we will use OpenStreetMap to assess the potential damage to the road system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4355fca9-3e21-4556-a5d0-3e1577c68643",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dd18de-459a-4cb4-891e-cc3c98e76e7a",
   "metadata": {},
   "source": [
    "- To understand the use of **OSMnx** to extract geospatial data from OpenStreetmap.\n",
    "- To know how to download data from the Copernicus Climate Data Store using the `cdsapi` and access it through Python.\n",
    "- To know how to access and open information from the Copernicus Land Monitoring System. Specifically the Corine Land Cover data.\n",
    "\n",
    "- To be able to open and visualize this hazard data.\n",
    "- To know how to rasterize vector data through using **Geocube**.\n",
    "- To know how to visualise vector and raster data.\n",
    "- To understand the basic functioning of **Matplotlib** to create a map.\n",
    "\n",
    "- To understand the basic approach of a natural hazard risk assessment.\n",
    "- To be able to use the `DamageScanner` to do a damage assessment.\n",
    "- To interpret and compare the damage estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7cd45-4394-44fb-ba1b-e52464223d42",
   "metadata": {},
   "source": [
    "## 1. Introducing the packages\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d01ad-b5d4-4486-9d00-04fd00142a19",
   "metadata": {},
   "source": [
    "Within this tutorial, we are going to make use of the following packages: \n",
    "\n",
    "[**GeoPandas**](https://geopandas.org/) is a Python package that extends the datatypes used by pandas to allow spatial operations on geometric types.\n",
    "\n",
    "[**OSMnx**](https://osmnx.readthedocs.io/) is a Python package that lets you download geospatial data from OpenStreetMap and model, project, visualize, and analyze real-world street networks and any other geospatial geometries. You can download and model walkable, drivable, or bikeable urban networks with a single line of Python code then easily analyze and visualize them. You can just as easily download and work with other infrastructure types, amenities/points of interest, building footprints, elevation data, street bearings/orientations, and speed/travel time.\n",
    "\n",
    "[**NetworkX**](https://networkx.org/) is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.\n",
    "\n",
    "[**Matplotlib**](https://matplotlib.org/) is a comprehensive Python package for creating static, animated, and interactive visualizations in Python. Matplotlib makes easy things easy and hard things possible.\n",
    "\n",
    "[**Geocube**](https://corteva.github.io/geocube) is a Python package to convert geopandas vector data into rasterized data.\n",
    "\n",
    "[**xarray**](https://docs.xarray.dev/) is a Python package that allows for easy and efficient use of multi-dimensional arrays.\n",
    "\n",
    "Import the packages in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d683ee-d2b5-49a5-9b31-9ab50039f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cdsapi\n",
    "import shapely \n",
    "import matplotlib\n",
    "import urllib3\n",
    "import pyproj\n",
    "import contextily as cx\n",
    "\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "\n",
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3208479-d07e-4d6d-afd7-a9944b9630c0",
   "metadata": {},
   "source": [
    "Import error? Not all of the packages were installed already. Make sure to install the missing packages using pip install in the cell below and then run the cell above again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395181b-53d5-48de-84ff-55e27da494a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # provide code to pip install missing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981898d2-5f8f-4990-a236-b1cfe2c7008e",
   "metadata": {},
   "source": [
    "## 2. Downloading and accessing natural hazard data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7693fcc-a0cf-4ed4-a0d0-e3a00b917547",
   "metadata": {},
   "source": [
    "We will first download and explore windstorm and flood data for the Netherlands. \n",
    "\n",
    "### Windstorm Data\n",
    "<hr>\n",
    "\n",
    "The windstorm data will be downloaded from the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu/). As we have seen during the lecture, and as you can also see by browsing on this website, there is an awful lot of climate data available through this Data Store. As such, it is very valuable to understand how to access and download this information to use within an analysis. To keep things simple, we only download one dataset today: [A winter windstorm](https://cds.climate.copernicus.eu/cdsapp#!/dataset/sis-european-wind-storm-indicators?tab=overview). \n",
    "\n",
    "We will do so using an **API**, which is the acronym for application programming interface. It is a software intermediary that allows two applications to talk to each other. APIs are an accessible way to extract and share data within and across organizations. APIs are all around us. Every time you use a rideshare app, send a mobile payment, or change the thermostat temperature from your phone, youâ€™re using an API.\n",
    "\n",
    "However, before we can access this **API**, we need to take a few steps. Most importantly, we need to register ourselves on the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu/) portal. To do so, we need to register, as explained in the video clip below:\n",
    "\n",
    "<img src=\"https://github.com/ElcoK/BigData_AED/blob/main/_static/images/CDS_registration.gif?raw=1\" class=\"bg-primary mb-1\">\n",
    "<br>\n",
    "\n",
    "Now, the next step is to access the API. You can now login on the website of the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu/). After you login, you can click on your name in the top right corner of the webpage (next to the login button). On the personal page that has just opened, you will find your user ID (**uid**) and your personal **API**. You need to add those in the cell below to be able to download the windstorm.\n",
    "\n",
    "As you can see in the cell below, we download a specific windstorm that has occured on the 28th of October in 2013. This is storm [Carmen (also called St Jude)](https://en.wikipedia.org/wiki/St._Jude_storm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4736833f-c0ec-48f4-8c29-1721ba2ecb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = XXX\n",
    "apikey = 'XXX'\n",
    "\n",
    "c = cdsapi.Client(key=f\"{uid}:{apikey}\", url=\"https://cds.climate.copernicus.eu/api/v2\")\n",
    "\n",
    "c.retrieve(\n",
    "    'sis-european-wind-storm-indicators',\n",
    "    {\n",
    "        'variable': 'all',\n",
    "        'format': 'zip',\n",
    "        'product': 'windstorm_footprints',\n",
    "        'year': '2013',\n",
    "        'month': '10',\n",
    "        'day': '28',\n",
    "    },\n",
    "    'Carmen.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec192f1-8ac1-4e61-ac8f-c01d496e157f",
   "metadata": {},
   "source": [
    "### Flood Data\n",
    "<hr>\n",
    "\n",
    "The flood data we will extract from a repository maintained by the European Commission Joint Research Centre. We will download river flood hazard maps from their [Flood Data Collection](https://data.jrc.ec.europa.eu/dataset/1d128b6c-a4ee-4858-9e34-6210707f3c81). \n",
    "\n",
    "Here we do not need to use an API and we also do not need to register ourselves, so we can download any of the files directly. To do so, we use the `urllib` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f3b19-cba4-4f4a-a902-082e396b7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the link to the 1/100 flood map for Europe\n",
    "zipurl = 'https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/FLOODS/EuropeanMaps/floodMap_RP100.zip'\n",
    "\n",
    "# and now we open and extract the data\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8baa489-3b9c-4d16-afdf-359651d2f6ba",
   "metadata": {},
   "source": [
    "The download and zip in the cell above sometimes does not work. If that is indeed the case (e.g., when it seems to remain stuck), download the files manually through the link and upload them in the data folder for this week (as explained at the start of this tutorial.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb3103-bc54-4670-9936-f299561190f6",
   "metadata": {},
   "source": [
    "### Set location to explore\n",
    "---\n",
    "Before we continue, we need to specify our location of interest. This should be a province that will have some flooding and relative high wind speeds occuring (else we will find zero damage). We specify the region of interest in the cell below by using the `geocode_to_gdf()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb7b64e-de75-4490-ac72-bad321d4da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name = \"Gelderland, The Netherlands\" ### But you could also consider Zeeland, for example.\n",
    "area = ox.geocode_to_gdf(place_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd3821f-16dd-4e7b-8ac6-a46475704afd",
   "metadata": {},
   "source": [
    "## 3. Exploring the natural hazard data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e203b2-e4c0-458a-a91e-9218614baeab",
   "metadata": {},
   "source": [
    "Now we will explore our natural hazard data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d77ba-32df-44c4-a565-b197b7e4cefc",
   "metadata": {},
   "source": [
    "### Windstorm Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b379bcc-84a2-4bb6-86a6-d0e3ad0d1c84",
   "metadata": {},
   "source": [
    "As you can see in the section above, we have downloaded the storm footprint in a zipfile. Let's open the zipfile and load the dataset using the `xarray` package through the `open_dataset()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d33537-8db8-4def-89ee-2387ec993831",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('Carmen.zip') as zf:\n",
    "    \n",
    "    # Let's get the filename first\n",
    "    file = zf.namelist()[0]\n",
    "    \n",
    "    # And now we can open and select the file within Python\n",
    "    with zf.open(file) as f:\n",
    "        windstorm_europe = xr.open_dataset(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375410e2-ebe5-4f4d-b924-ad15e8fb9d59",
   "metadata": {},
   "source": [
    "Let's have a look at the storm we have downloaded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35bb91-0705-4d80-b063-adabc74cc353",
   "metadata": {},
   "outputs": [],
   "source": [
    "windstorm_europe['FX'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092e7f97-cf7a-4000-818f-1a73e578b0ec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 1:</b> Describe windstorm Carmen. When did this event happen, which areas were most affected? Can you say something about the maximum wind speeds in different areas, based on the plot? And what does FX mean?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e8caf3-c5c3-4970-b923-b58d1fe007f8",
   "metadata": {},
   "source": [
    "Unfortunately, our data does not have a proper coordinate system defined yet. As such, we will need to use the `rio.write_crs()` function to set the coordinate system to **EPSG:4326** (the standard global coordinate reference system). \n",
    "\n",
    "We also need to make sure that the functions will know what the exact parameters are that we have to use for our spatial dimenions (e.g. longitude and latitude). It prefers to be named `x` and `y`. So we use the `rename()` function before we use the `set_spatial_dims()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7b6ec-a394-4e3c-82dd-8a59ce029563",
   "metadata": {},
   "outputs": [],
   "source": [
    "windstorm_europe.rio.write_crs(4326, inplace=True)\n",
    "windstorm_europe = windstorm_europe.rename({'Latitude': 'y','Longitude': 'x'})\n",
    "windstorm_europe.rio.set_spatial_dims(x_dim=\"x\",y_dim=\"y\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e41966-7273-4521-9b27-4c9498a66e0b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 2:</b> Climate data is often stored as a netCDF file. Please describe what a netCDF file is. Which information is stored in the netCDF file we have downloaded for the windstorm? What type of metadata does it contain?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba5e684-f658-42e9-bded-bbb47ced24e4",
   "metadata": {},
   "source": [
    "Following, we also make sure it will be in the European coordinate system **EPSG:3035** to ensure we can easily use it together with the other data. To do so, we use the `rio.reproject()` function. You can simple add the number of the coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b276083-7825-4576-832b-129566f65222",
   "metadata": {},
   "outputs": [],
   "source": [
    "windstorm_europe = windstorm_europe. [add function]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0650103f-eed7-43f6-b9ef-a221781e356a",
   "metadata": {},
   "source": [
    "Now we have all the information to clip the windstorm data to our area of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbfe52-1484-48fd-9dee-fc6064fe343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "windstorm_map = windstorm_europe.rio.clip(area.envelope.values, area.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c142f-2741-41bf-bace-96b6fede47f2",
   "metadata": {},
   "source": [
    "And let's have a look as well by using the `plot()` function. Please note that the legend is in meters per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b8e8ca-6a58-44df-8981-b040cc55b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "windstorm_map['FX']. [add function]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bded755-8d9b-41a0-bd6e-a25000bc7486",
   "metadata": {},
   "source": [
    "### Flood Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef96754-17bc-4d02-92ab-bb06280015a5",
   "metadata": {},
   "source": [
    "And similarly, we want to open the flood map. But now we do not have to unzip the file anymore and we can directly open it through using `xarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78db556-c66c-46a0-9615-b98e26b9e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_map_path = 'floodmap_EFAS_RP100_C.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555fab92-0c74-426e-bcfe-655cf6b25682",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_map = xr.open_dataset(flood_map_path, engine=\"rasterio\")\n",
    "flood_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb3c24d-4ed2-4717-befc-67e52e1bbbea",
   "metadata": {},
   "source": [
    "And let's make sure we set all the variables and the CRS correctly again to be able to open the data properly. Note that we should now use **EPSG:3035**. This is the standard coordinate system for Europe, in meters (instead of degrees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6de85-b165-4b7e-85ea-d09fe6bf9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_map.rio.write_crs(      , inplace=True)\n",
    "flood_map.rio.set_spatial_dims(x_dim=\"x\",y_dim=\"y\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebad344-dd4b-4c37-bafe-2464f11a79b2",
   "metadata": {},
   "source": [
    "Now it is pretty difficult to explore the data for our area of interest, so let's clip the flood data.  \n",
    "\n",
    "We want to clip our flood data to our chosen area. The code, however, is very inefficient and will run into memories issues on Google Colab. As such, we first need to clip it by using a bounding box, followed by the actual clip.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 3:</b> Please provide the lines of code below in which you show how you have clipped the flood map to your area.\n",
    "</div>\n",
    "\n",
    "*A few hints*:\n",
    "\n",
    "* carefully read the documentation of the `.clip_box()` function of rioxarray. Which information do you need? \n",
    "* is the GeoDataFrame of your region (the area GeoDataframe) in the same coordinate system? Perhaps you need to convert it using the `.to_crs()` function. \n",
    "* how do you get the bounds from your area GeoDataFrame? \n",
    "* The final step of the clip would be to use the `.rio.clip()` function, using the actual area file and the flood map clipped to the bounding box. Please note that you should **not** use the envelope here, like we did in the previous clip. Here we really want to use the exact geometry values.\n",
    "\n",
    "As you will see, we first clip it very efficiently using the bounding box. After that, we do an exact clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a22299-6507-45b3-b4ef-1321a193ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lon =  area.to_crs(epsg=3035).bounds.minx.values[0]\n",
    "min_lat = area.to_crs(epsg=3035).bounds.miny\n",
    "max_lon =  area.to_crs(epsg=3035).bounds\n",
    "max_lat =  area.to_crs(epsg=3035).\n",
    "\n",
    "flood_map_area = flood_map.rio.clip_box(minx=.... )\n",
    "flood_map_area = flood_map_area.rio.clip(area.XXXX.values, area.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744f4ff-e7c2-4b1b-b366-9ebd577f76bd",
   "metadata": {},
   "source": [
    "And let's have a look as well. Please note that the legend is in meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f23727-c8c0-4379-95f7-bc41ba5b3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_map_area['band_data'].plot(cmap='Blues',vmax=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c98ee1-d8f8-4eba-bfd2-36f26e849279",
   "metadata": {},
   "source": [
    "## 4. Downloading and exploring Land Cover data and Land Use data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0402ee8-6460-4db0-b216-b16b88ff2c56",
   "metadata": {},
   "source": [
    "We will explore rasterized Corine Land Cover data and land use data retrieved from OpenStreetMap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccebb6a-8c7b-4c7f-b974-899e15c9631b",
   "metadata": {},
   "source": [
    "### Download and access Copernicus Land Cover data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672472d8-aff1-498f-ac36-41082ac32c4e",
   "metadata": {},
   "source": [
    "Unfortunately, there is no API option to download the [Corine Land Cover](https://land.copernicus.eu/pan-european/corine-land-cover) data. We will have to download the data from the website first.\n",
    "\n",
    "To do so, we will first have to register ourselves again on the website. Please find in the video clip below how to register yourself on the website of the [Copernicus Land Monitoring Service](https://land.copernicus.eu/):\n",
    "\n",
    "<img src=\"https://github.com/ElcoK/BigData_AED/blob/main/_static/images/CLMS_registration.gif?raw=1\" class=\"bg-primary mb-1\">\n",
    "\n",
    "Now click on the Login button in the top right corner to login on the website. There are many interesting datasets on this website, but we just want to download the Corine Land Cover data, and specifically the latest version: [Corine Land Cover 2018](https://land.copernicus.eu/pan-european/corine-land-cover/clc2018?tab=download). To do so, please select the **Corine Land Cover - 100 meter**. Now click on the large green Download button. Your download should start any minute.\n",
    "\n",
    "Slightly annoying, the file you have downloaded is double zipped. Its slightly inconvenient to open this through Python and within Google Drive. So let's unzip it twice outside of Python (on your local machine) and then direct yourself to the `DATA` directory within the unzipped file. Here you can find a file called `U2018_CLC2018_V2020_20u1.tif`. Drop this file into this week's data directory, as specified at the start of this tutorial when we mounted our Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c9079-cde0-4be2-8b72-f7403d5f0e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLC_location = 'U2018_CLC2018_V2020_20u1.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa699e-1ba0-4ed8-9996-38d8cc81578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLC = xr.open_dataset(CLC_location, engine=\"rasterio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d263e20d-d88b-4cf3-ad5c-c1ff2d93ad6b",
   "metadata": {},
   "source": [
    "Similarly to the flood map data, we need to do a two-stage clip again (like we did before in this tutorial to ensure we get only our area of interest without exceeding our RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299869a-2724-44c6-b5af-d134f7b9aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLC_region = CLC.rio.clip_box(\n",
    "CLC_region = CLC_region.rio.clip("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706a9da-4336-4f06-a8a7-4c825639dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLC_region = CLC_region.rename({'x': 'lat','y': 'lon'})\n",
    "CLC_region.rio.set_spatial_dims(x_dim=\"lat\",y_dim=\"lon\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31c0989-e96e-4809-a24d-13ab00de751f",
   "metadata": {},
   "source": [
    "Our next step is to prepare the visualisation of a map. What better way to explore land-cover information than plotting it on a map? \n",
    "\n",
    "As you will see below, we can create a dictionary with color codes that will color each land-cover class based on the color code provided in this dictionary. We use the colorscheme of Corine Land Cover. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198958ec-68a5-44d2-9b8c-91a2dd19484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLC_values = [111, 112, 121, 122, 123, 124, 131, 132, 133, 141, 142, 211, 212, 213, 221, 222, 223, 231, 241, 242,\n",
    " 243, 244, 311, 312, 313, 321, 322, 323, 324, 331, 332, 333, 334, 335, 411, 412, 421, 422, 423, 511, 512, 521, 522, 523]\n",
    "\n",
    "CLC_colors = ['#E6004D', '#FF0000', '#CC4DF2', '#CC0000', '#E6CCCC', '#E6CCE6', '#A600CC', '#A64DCC', '#FF4DFF', '#FFA6FF', '#FFE6FF', '#FFFFA8', '#FFFF00', '#E6E600',\n",
    " '#E68000', '#F2A64D', '#E6A600', '#E6E64D', '#FFE6A6', '#FFE64D', '#E6CC4D', '#F2CCA6', '#80FF00', '#00A600',\n",
    " '#4DFF00', '#CCF24D', '#A6FF80', '#A6E64D', '#A6F200', '#E6E6E6', '#CCCCCC', '#CCFFCC', '#000000', '#A6E6CC',\n",
    " '#A6A6FF', '#4D4DFF', '#CCCCFF', '#E6E6FF', '#A6A6E6', '#00CCF2', '#80F2E6', '#00FFA6', '#A6FFE6', '#E6F2FF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c9c52",
   "metadata": {},
   "source": [
    "The code below allows us the use the color_dict above to plot the CLC map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b50772-57d5-4e49-a600-00bfeaf9ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict_raster = dict(zip(CLC_values,CLC_colors))\n",
    "\n",
    "# We create a colormar from our list of colors\n",
    "cm = ListedColormap(CLC_colors)\n",
    "\n",
    "# Let's also define the description of each category : 1 (blue) is Sea; 2 (red) is burnt, etc... Order should be respected here ! Or using another dict maybe could help.\n",
    "labels = np.array(CLC_values)\n",
    "len_lab = len(labels)\n",
    "\n",
    "# prepare normalizer\n",
    "## Prepare bins for the normalizer\n",
    "norm_bins = np.sort([*color_dict_raster.keys()]) + 0.5\n",
    "norm_bins = np.insert(norm_bins, 0, np.min(norm_bins) - 1.0)\n",
    "\n",
    "## Make normalizer and formatter\n",
    "norm = matplotlib.colors.BoundaryNorm(norm_bins, len_lab, clip=True)\n",
    "fmt = matplotlib.ticker.FuncFormatter(lambda x, pos: labels[norm(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68baa525-98be-4069-8129-dc6c22db4793",
   "metadata": {},
   "source": [
    "And let's plot the Corine Land Cover data for our area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a977453-9180-4de6-872e-1fe7818f2915",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(14,10))\n",
    "\n",
    "CLC_region[\"band_data\"].plot(ax=ax,levels=len(CLC_colors),colors=CLC_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465c4b28-3d01-4960-bb7c-8709a0c023bc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 4:</b> Describe the different land-use classes within your region that you see on the Corine Land Cover map. Do you see any dominant land-use classes? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8867d41e-2b7b-40c2-8576-611f2c04f547",
   "metadata": {},
   "source": [
    "### Extract and visualize land-use information from OpenStreetMap\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0dd8ab-15e8-494d-a6fb-3861636e5ed4",
   "metadata": {},
   "source": [
    "The next step is to define which area you want to focus on. In the cell below, you will now read \"Kampen, The Netherlands\". Change this to any area or municipality in the Netherlands that (1) you can think of and (2) will work. \n",
    "\n",
    "In some cases, the function does not recognize the location. You could either try a different phrasing or try a different location. Many parts of the Netherlands should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12189f0d-5f9f-4ada-922a-6fc12f9bbf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name = \"Kampen, The Netherlands\"\n",
    "area = ox.geocode_to_gdf(place_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2077d677-c8c2-4fd5-b0d0-21fad4f3eec5",
   "metadata": {},
   "source": [
    "Now let us visualize the bounding box of the area. As you will notice, we also estimate the size of the area. If the area size is above 50km2, or when you have many elements within your area (for example the amsterdam city centre), extracting the data from OpenStreetMap may take a little while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50447dc3-9d91-4a64-adea-90cbb0e0a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_to_check = area.to_crs(epsg=3857)\n",
    "ax = area_to_check.plot(figsize=(10, 10), color=\"none\", edgecolor=\"k\", linewidth=4)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_axis_off()\n",
    "cx.add_basemap(ax, zoom=11)\n",
    "\n",
    "size = int(area_to_check.area/1e6)\n",
    "\n",
    "ax.set_title(\"{}. Total area: {} km2\".format(place_name,size),fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154abf9-c923-4253-9e97-e8c91fe9d632",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 5:</b> To make sure we understand which area you focus on, please submit the figure that outlines your area.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b5084-08f0-471d-8982-06b340e5d3f5",
   "metadata": {},
   "source": [
    "Now we are satisfied with the selected area, we are going to extract the land-use information from OpenStreetMap. To find the right information from OpenStreetMap, we use **tags**.\n",
    "\n",
    "As you will see in the cell below, we use the tags *\"landuse\"* and *\"natural\"*. We need to use the *\"natural\"* tag to ensure we also obtain water bodies and other natural elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f52137d-bf2c-4405-9df1-42ac73a5d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {'landuse': True, 'natural': True}   \n",
    "landuse = ox.features_from_place(place_name, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f44095d-c47c-49d4-ac8d-6a91eae8f1ae",
   "metadata": {},
   "source": [
    "In case the above does not work, you can continue the assignment by using the code below (make sure you remove the hashtags to run it). If you decide to use the data as specified below, also change the map at the start to 'Kampen'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd17e2-d990-447a-b3d4-75dbe2b93ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote_url = 'https://github.com/ElcoK/BigData_AED/raw/main/week5/kampen_landuse.gpkg'\n",
    "# file = 'kampen_landuse.gpkg'\n",
    "\n",
    "# request.urlretrieve(remote_url, file)\n",
    "#landuse = gpd.GeoDataFrame.from_file('kampen_landuse.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9e972-55b9-45a9-b727-45066032e900",
   "metadata": {},
   "source": [
    "To ensure we really only get the area that we want, we use geopandas's `clip` function to only keep the area we want. This function does exactly the same as the `clip` function in QGIS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be7294-2cc6-4997-9c62-a5aea3fd1c29",
   "metadata": {},
   "source": [
    "When we want to visualize or analyse the data, we want all information in a single column. However, at the moment, all information that was tagged as *\"natural\"*, has no information stored in the *\"landuse\"* tags. It is, however, very convenient if we can just use a single column for further exploration of the data. \n",
    "\n",
    "To overcome this issue, we need to add the missing information to the landuse column, as done below. Let's first have a look which categories we have in the **natural** column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed6e32f-06a7-4189-8e77-efd1a9cf77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse.natural.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6a6af-c3db-450b-944c-95c7cef1fd32",
   "metadata": {},
   "source": [
    "And now we can add them to the **landuse** column. We made a start, but its up to you to fill in the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b14f7a-f62d-4575-ad02-39f279fde5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse.loc[landuse.natural=='water','landuse'] = 'water'\n",
    "landuse.loc[landuse.natural=='wetland','landuse'] = 'wetlands'\n",
    "\n",
    "\n",
    "landuse = landuse.dropna(subset=['landuse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851df40d-02d1-4409-9a89-9d1edcfa6bcd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 6:</b> Please provide in the answer box in Canvas the code that you used to make sure that all land uses are now registered within the landuse column.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead9126-edc3-41f1-80de-339e1e42dbda",
   "metadata": {},
   "source": [
    "We now create a *color_dict* like we have also done for the visualization of the land-use information to ensure we can visualize the data properly. This time, we use our own colorscheme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64197848-0d42-480e-9d7f-4a68bff63772",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {  \"grass\":'#c3eead',               \"railway\": \"#000000\",\n",
    "                \"forest\":'#1c7426',              \"orchard\":'#fe6729',\n",
    "                \"residential\":'#f13013',         \"industrial\":'#0f045c',\n",
    "                \"retail\":'#b71456',              \"education\":'#d61181',              \n",
    "                \"commercial\":'#981cb8',          \"farmland\":'#fcfcb9',\n",
    "                \"cemetery\":'#c39797',            \"construction\":'#c0c0c0',\n",
    "                \"meadow\":'#c3eead',              \"farmyard\":'#fcfcb9',\n",
    "                \"plant_nursery\":'#eaffe2',       \"scrub\":'#98574d',\n",
    "                \"allotments\":'#fbffe2',          \"reservoir\":'#8af4f2',\n",
    "                \"static_caravan\":'#ff3a55',      \"wetlands\": \"#c9f5e5\",\n",
    "                \"water\": \"#c9e5f5\",              \"beach\": \"#ffeead\",\n",
    "                \"landfill\" : \"#B08C4D\",          \"recreation_ground\" : \"#c3eead\",\n",
    "                \"brownfield\" : \"#B08C4D\",        \"village_green\" : \"#f13013\" ,\n",
    "                \"military\": \"#52514E\",            \"garden\" : '#c3eead'\n",
    "             } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408cdac8-2ca1-4eef-8997-8c83b852f5c5",
   "metadata": {},
   "source": [
    "Unfortunately, OpenSteetMap very often contains elements that have a unique tag. As such, it may be the case that some of our land-use categories are not in the dictionary yet. \n",
    "\n",
    "Let's first create an overview of the unique land-use categories within our data through using the `.unique()` function within our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c41069-fb2c-4606-adcc-e73ab95778ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse.landuse.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f354fe05-b608-435f-acf4-6310886071dd",
   "metadata": {},
   "source": [
    "Ofcourse we can visually compare the array above with our color_dict, but it is much quicker to use `Sets` to check if there is anything missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba31d28-3398-4d33-a325-eab786869020",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(landuse.landuse.unique())-set(color_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2de6c7-180e-43b3-ab32-ee7df7ff6ea2",
   "metadata": {},
   "source": [
    "In case anything is missing, add them to the color_dict dictionairy and re-run that cell. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 7:</b> Show us in Canvas (i) which land-use categories you had to add, and (ii) how your final color dictionary looks like.\n",
    "</div>\n",
    "\n",
    "```{tip}\n",
    "You can easily find hexcodes online to find the right colour for each land-use category. Just google hexcodes!\n",
    "```\n",
    "\n",
    "\n",
    "Our next step is to make sure that we can connect our color codes to our dataframe with land-use categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45093fa0-b95b-49e1-bb32-d149ba424931",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {key: color_dict[key]\n",
    "             for key in color_dict if key not in  list(set(color_dict)-set(landuse.landuse.unique()))}\n",
    "\n",
    "map_dict = dict(zip(color_dict.keys(),[x for x in range(len(color_dict))]))\n",
    "\n",
    "landuse['col_landuse'] = landuse.landuse.apply(lambda x: color_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010bec6f-fd76-40d2-a38c-be266e57d056",
   "metadata": {},
   "source": [
    "Now we can plot the figure!\n",
    "\n",
    "As you will see in the cell below, we first state that we want to create a figure with a specific figure size. You can change the dimensions to your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f01254-e1d7-4e3f-b40c-b2358223670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(12,10))\n",
    "\n",
    "# add color scheme\n",
    "color_scheme_map = list(color_dict.values())\n",
    "cmap = LinearSegmentedColormap.from_list(name='landuse',\n",
    "                                     colors=color_scheme_map)  \n",
    "\n",
    "# and plot the land-use map.\n",
    "landuse.plot(color=landuse['col_landuse'],ax=ax,linewidth=0)\n",
    "\n",
    "# remove the ax labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_axis_off()\n",
    "\n",
    "# add a legend:\n",
    "legend_elements = []\n",
    "for iter_,item in enumerate(color_dict):\n",
    "    legend_elements.append(Patch(facecolor=color_scheme_map[iter_],label=item))        \n",
    "\n",
    "ax.legend(handles=legend_elements,edgecolor='black',facecolor='#fefdfd',prop={'size':12},loc=(1.02,0.2)) \n",
    "\n",
    "# add a title\n",
    "ax.set_title(place_name,fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ca96a-2ec2-4889-b30b-1f9d23cc0d18",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 8:</b> Please upload a figure of your land-use map, using OpenStreetMap. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99777639-4201-42aa-ab97-1705bed60392",
   "metadata": {},
   "source": [
    "### Rasterize land-use information\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8bda0f-aea9-471c-af15-31d9bf2bd191",
   "metadata": {},
   "source": [
    "As you have noticed already during the lecture, and as we have seen during TAA1 with the Google Earth Engine, most land-use data is in raster format. \n",
    "\n",
    "In OpenStreetMap everything is stored in vector format. As such, the land-use information we extracted from OpenStreetMap is also in vector format. While it is not always necessary to have this information in raster format, it is useful to know how to convert your data into a raster format.\n",
    "\n",
    "To do so, we can make use of the **GeoCube** package, which is a recently developed Python package that can very easily convert vector data into a raster format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d84eb30-2657-4cd3-8300-be6e22673d11",
   "metadata": {},
   "source": [
    "The first thing we will need to do is to define all the unique land-use classes and store them in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d1662b-23a0-443d-8465-0acad5e374c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_enums = {'landuse': landuse.landuse.drop_duplicates().values.tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17845c5f-ec24-498c-a185-1cbf5d4054dd",
   "metadata": {},
   "source": [
    "And now we simply use the `make_geocube()` function to convert our vector data into raster data. \n",
    "\n",
    "In the `make_geocube()` function, we have to specify several arguments:\n",
    "\n",
    "- Through the `vector_data` argument we have to state which dataframe we want to rasterize.\n",
    "- Through the `output_crs` argument we have to state the coordinate reference system (CRS). We use the OpenStreetMap default EPSG:4326.\n",
    "- Through the `resolution` argument we have to state the resolution. In our case, we will have to set this in degrees. 0.01 degrees is equivalent to roughly 10km around the equator. \n",
    "- Through the `categorical_enums` argument we specify the different land-use categories.\n",
    "\n",
    "Play around with the different resolutions to find the level of detail. The higher the resolution (i.e., the more zeros behind the comma), the longer it will take to rasterize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca109c1-5169-4833-818d-bae97f0b33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse_grid = make_geocube(\n",
    "    vector_data=,\n",
    "    output_crs=,\n",
    "    resolution=(-XXXX, XXXX),\n",
    "    categorical_enums=categorical_enums\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ea735-0255-4b44-ab66-210bf3655213",
   "metadata": {},
   "source": [
    "Let's explore what this function has given us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca50588-074b-4217-a384-f582a57f6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse_grid[\"landuse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35204590-9e19-45a0-8065-4e453d024d69",
   "metadata": {},
   "source": [
    "The output above is a typical output of the **xarray** package. \n",
    "\n",
    "- The `array` shows the numpy array with the actual values. As you can see, the rasterization process has used the value `-1` for NoData. \n",
    "- The `Coordinates` table shows the x (longitude) and y (latitude) coordinates of the array. It has the exact same size as the `array` with land-use values.\n",
    "- The `Attributes` table specifies the NoData value (the `_FillValue` element, which indeed shows `-1`) and the name of the dataset.\n",
    "\n",
    "Now let's plot the data to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f75e9-4747-43e1-93a0-d1b63d90378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(14,10))\n",
    "\n",
    "landuse_grid[\"landuse\"].plot(ax=ax,vmin=0,vmax=15,levels=15,cmap='tab20')\n",
    "\n",
    "# remove the ax labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_axis_off()\n",
    "\n",
    "#add a title\n",
    "\n",
    "ax.set_title('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b1ce7-f6e6-410d-be82-e24e9d224bd3",
   "metadata": {},
   "source": [
    "As we can see in the figure above, the land-use categories have turned into numbers, instead of land-use categories described by a string value. \n",
    "\n",
    "This is of course a lot harder to interpret. Let's re-do some parts to make sure we can properly link them back to the original data.\n",
    "\n",
    "To do so, we will first need to make sure that we know which values (numbers) are connected to each land-use category. Instead of trying to match, let's predefine this ourselves!\n",
    "\n",
    "We will start with creating a dictionary that allows us to couple a number to each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882f6c1-9008-4815-b19f-7ec2771aaa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dict = dict(zip(landuse.landuse.unique(),np.arange(0,len(landuse.landuse.unique()),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b572e0-d97b-47cb-8fa7-1a2c11afc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dict['nodata'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4797d-9d48-4c83-a564-936d579dc256",
   "metadata": {},
   "source": [
    "And we now use this dictionary to add a new column to the dataframe with the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b7dd2-84df-428c-9c70-7d07aa745346",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse_valued = make_geocube(\n",
    "    vector_data=XXXX,\n",
    "    output_crs=XXXX,\n",
    "    resolution=(-XXXX, XXXX),\n",
    "    categorical_enums={'landuse_value': landuse.landuse_value.drop_duplicates().values.tolist()\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510409be-3b7f-4f75-848b-4146bee15338",
   "metadata": {},
   "source": [
    "And let's use the original `color_dict` dictionary to find the right hex codes for each of the land-use categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458b393b-47e8-44a3-bebc-148b4d764401",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = landuse.landuse.drop_duplicates().values.tolist()\n",
    "colormap_raster = [color_dict[lu_class] for lu_class in unique_classes] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8197f4b9-9c0f-4999-89f3-1ea657888193",
   "metadata": {},
   "source": [
    "To plot the new result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb9d2c-2435-485f-8daa-6c54e29e8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(14,10))\n",
    "\n",
    "landuse_valued[\"landuse_value\"].plot(ax=ax,vmin=0,vmax=19,levels=len(unique_classes),colors=colormap_raster)\n",
    "\n",
    "# remove the ax labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_axis_off()\n",
    "\n",
    "# add title\n",
    "ax.set_title('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e42dd3a-c0c3-496f-bbc4-dbdf1f3901d1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 9:</b> In the rasterization process, we use the `.make_geocube()` function. Please elaborate on the following: i)why is it important to specify the right coordinate system? What could happen if you choose the wrong coordinate system? ii) which resolution did you choose and why? iii)Why did the first result did not give us the right output with the correct colors? How did you solve this? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8789a06-d041-4d6f-aab7-48032ac8c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = landuse.landuse.drop_duplicates().values.tolist()\n",
    "colormap_raster = [color_dict[lu_class] for lu_class in unique_classes] \n",
    "color_dict_raster = dict(zip(np.arange(-1,len(landuse.landuse.unique())+1,1),['#ffffff']+colormap_raster))\n",
    "\n",
    "# We create a colormar from our list of colors\n",
    "cm = ListedColormap([color_dict_raster[x] for x in color_dict_raster.keys()])\n",
    "\n",
    "# Let's also define the description of each category. Order should be respected here!\n",
    "labels = np.array(['nodata'] + unique_classes)\n",
    "len_lab = len(labels)\n",
    "\n",
    "# prepare normalizer\n",
    "## Prepare bins for the normalizer\n",
    "norm_bins = np.sort([*color_dict_raster.keys()]) + 0.5\n",
    "norm_bins = np.insert(norm_bins, 0, np.min(norm_bins) - 1.0)\n",
    "\n",
    "## Make normalizer and formatter\n",
    "norm = matplotlib.colors.BoundaryNorm(norm_bins, len_lab, clip=True)\n",
    "fmt = matplotlib.ticker.FuncFormatter(lambda x, pos: labels[norm(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36beb42-1da5-4da0-bb02-b61604b0852f",
   "metadata": {},
   "source": [
    "Let's plot the map again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def51260-e57c-4957-8263-2b43a83a134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(14,10))\n",
    "\n",
    "ax = landuse_valued[\"landuse_value\"].plot(levels=len(unique_classes), cmap=cm, norm=norm)\n",
    "\n",
    "# remove the ax labels\n",
    "diff = norm_bins[1:] - norm_bins[:-1]\n",
    "tickz = norm_bins[:-1] + diff / 2\n",
    "cb = fig.colorbar(ax, format=fmt, ticks=tickz)\n",
    "\n",
    "# set title again\n",
    "fig.axes[0].set_title('')\n",
    "\n",
    "fig.axes[0].set_xticks([])\n",
    "fig.axes[0].set_yticks([])\n",
    "fig.axes[0].set_axis_off()\n",
    "\n",
    "# for some weird reason we get two colorbars, so we remove one:\n",
    "fig.delaxes(fig.axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a2267-4057-485c-85f1-1929896ad9ee",
   "metadata": {},
   "source": [
    "## 5. Perform a raster-based damage assessment using OSM and Corine Land Cover\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfabe80-3c8f-4e3a-a411-a29349c2d75b",
   "metadata": {
    "id": "Agxq2HqY-g4H"
   },
   "source": [
    "To calculate the potential damage to both windstorms and floods, we use stage-damage curves, which relate the intensity of the hazard to the fraction of maximum damage that can be sustained by a certain land use. As you can see on the Corine Land Cover map that we just plotted, there are a lot of land use classes (44), though not all will suffer damage from either the windstorm or the flood event. For each of the land-use classes a curve and a maximum damage number are assigned.\n",
    "\n",
    "To Assess the damage for both the flood and windstorm event, we are going to make use of the [DamageScanner](https://damagescanner.readthedocs.io/en/latest/), which is a tool to calculate potential flood damages based on inundation depth and land use using depth-damage curves in the Netherlands. The DamageScanner was originally developed for the 'Netherlands Later' project [(Klijn et al., 2007)](https://www.rivm.nl/bibliotheek/digitaaldepot/WL_rapport_Overstromingsrisicos_Nederland.pdf).  The original land-use classes were based on the Land-Use Scanner in order to evaluate the effect of future land-use change on flood damages. We have tailored the input of the DamageScanner to make sure it can estimate the damages using Corine Land Cover.\n",
    "\n",
    "Because the simplicity of the model, we can use this for any raster-based hazard map with some level of intensity. Hence, we can use it for both hazards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b5f52-bbad-42a6-acd5-1ea0248591f8",
   "metadata": {
    "id": "5m_RAcp_fraF"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 10:</b>  Describe in your own words what the `DamageScanner()` function does. Please walk us through the different steps. Which inputs do you need to be able to run this damage assessment?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d33d66-6bf6-43b2-8c24-3e1a1069af2b",
   "metadata": {
    "id": "jDrTp44Q-g4H"
   },
   "outputs": [],
   "source": [
    "def DamageScanner(landuse_map,inun_map,curve_path,maxdam_path,cellsize=100):\n",
    "        \n",
    "    # load land-use map\n",
    "    landuse = landuse_map.copy()\n",
    "    \n",
    "    # Load inundation map\n",
    "    inundation = inun_map.copy()\n",
    "    \n",
    "    inundation = np.nan_to_num(inundation)        \n",
    "\n",
    "    # Load curves\n",
    "    if isinstance(curve_path, pd.DataFrame):\n",
    "        curves = curve_path.values   \n",
    "    elif isinstance(curve_path, np.ndarray):\n",
    "        curves = curve_path\n",
    "\n",
    "    #Load maximum damages\n",
    "    if isinstance(maxdam_path, pd.DataFrame):\n",
    "        maxdam = maxdam_path.values \n",
    "    elif isinstance(maxdam_path, np.ndarray):\n",
    "        maxdam = maxdam_path\n",
    "        \n",
    "    # Speed up calculation by only considering feasible points\n",
    "    inun = inundation * (inundation>=0) + 0\n",
    "    inun[inun>=curves[:,0].max()] = curves[:,0].max()\n",
    "    waterdepth = inun[inun>0]\n",
    "    landuse = landuse[inun>0]\n",
    "\n",
    "    # Calculate damage per land-use class for structures\n",
    "    numberofclasses = len(maxdam)\n",
    "    alldamage = np.zeros(landuse.shape[0])\n",
    "    damagebin = np.zeros((numberofclasses, 4,))\n",
    "    for i in range(0,numberofclasses):\n",
    "        n = maxdam[i,0]\n",
    "        damagebin[i,0] = n\n",
    "        wd = waterdepth[landuse==n]\n",
    "        alpha = np.interp(wd,((curves[:,0])),curves[:,i+1])\n",
    "        damage = alpha*(maxdam[i,1]*cellsize)\n",
    "        damagebin[i,1] = sum(damage)\n",
    "        damagebin[i,2] = len(wd)\n",
    "        if len(wd) == 0:\n",
    "            damagebin[i,3] = 0\n",
    "        else:\n",
    "            damagebin[i,3] = np.mean(wd)\n",
    "        alldamage[landuse==n] = damage\n",
    "\n",
    "    # create pandas dataframe with output\n",
    "    loss_df = pd.DataFrame(damagebin.astype(float),columns=['landuse','losses','area','avg_depth']).groupby('landuse').sum()\n",
    "    \n",
    "    # return output\n",
    "    return loss_df.sum().values[0],loss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c6b79-ce68-436b-a7fb-8a889528f513",
   "metadata": {
    "id": "Y7PB8oJz-g4H"
   },
   "source": [
    "### Windstorm Damage\n",
    "---\n",
    "To estimate the potential damage of our windstorm, we use the vulnerability curves developed by [Yamin et al. (2014)](https://www.sciencedirect.com/science/article/pii/S2212420914000466). Following [Yamin et al. (2014)](https://www.sciencedirect.com/science/article/pii/S2212420914000466), we will apply a sigmoidal vulnerability function satisfying two constraints: (i) a minimum threshold for the occurrence of damage with an upper bound of 100% direct damage; (ii) a high power-law function for the slope, describing an increase in damage with increasing wind speeds. Due to the limited amount of vulnerability curves available for windstorm damage, we will use the damage curve that represents low-rise *reinforced masonry* buildings for all land-use classes that may contain buildings. Obviously, this is a large oversimplification of the real world, but this should be sufficient for this exercise. When doing a proper stand-alone windstorm risk assessment, one should take more effort in collecting the right vulnerability curves for different building types.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e63daa-636b-4a1e-ba6c-5bb78e56f290",
   "metadata": {
    "id": "-RxvAEQh-g4H",
    "tags": []
   },
   "outputs": [],
   "source": [
    "wind_curves = pd.read_excel(\"https://github.com/VU-IVM/UNIGIS_ProgrammingGIS/tree/main/TAA2/damage_curves.xlsx\",sheet_name='wind_curves')\n",
    "maxdam = pd.read_excel(\"https://github.com/VU-IVM/UNIGIS_ProgrammingGIS/tree/main/TAA2/damage_curves.xlsx\",sheet_name='maxdam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4f312-c4fb-4169-b563-e5878dfd95e2",
   "metadata": {
    "id": "uLZ7vl1w-g4H"
   },
   "source": [
    "Unfortunately, we run into a *classic* problem when we want to overlay the windstorm data with the Corine Land Cover data. The windstorm data is not only stored in a different coordinate system (we had to convert it from **EPSG:4326** to **EPSG:3035**), it is in a different resolution (**1km** instead of the **100m** of Corine Land Cover).  \n",
    "\n",
    "Let's first have a look how our clipped data look's like. If you have decided to use Gelderland, you will see that we have 102 columns (our Lattitude/lat) and 74 rows (our Longitude/lon). If you scroll above to our Corine Land Cover data, you see that dimensions are different: 1270 columns (Lattitude/lat/x) and 870 rows (Longitude/lon/y). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bc4345-b1e5-45c7-8aa2-95ef39b1ea78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "gG2OXOySj8Ra",
    "outputId": "67135491-52de-4571-f8c9-7b6a74e19b66"
   },
   "outputs": [],
   "source": [
    "windstorm_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1688219-1647-442e-8ed7-e4277ca75a16",
   "metadata": {
    "id": "igfFBqcK-g4H"
   },
   "source": [
    "The first thing we are going to do is try to make sure our data will be in the correct resolution (moving from **1km** to **100m**). To do so, we will use the `rio.reproject()` function. You will see that specify the resolution as **100**. Because **EPSG:3035** is a coordinate system in meters, we can simply use meters to define the resolution. We use the `rio.clip()` function to make sure we clip it again to our area of interest. The function below (`match_rasters`) will do the hard work for us. Please note all the input variables to understand what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d960af61-b324-459e-9e4c-da2f70bf7ecf",
   "metadata": {
    "id": "Kud2CWEDhz1O"
   },
   "outputs": [],
   "source": [
    "def match_rasters(hazard,landuse,haz_crs=3035,lu_crs=3035,resolution=100,hazard_col=['FX']):\n",
    "    \"\"\"\n",
    "    Clips, reprojections, and matches the resolutions of two rasters, `hazard` and `landuse`,\n",
    "    to prepare them for further analysis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hazard : xarray.DataArray\n",
    "        A 2D or 3D array containing hazard data.\n",
    "    landuse : xarray.DataArray\n",
    "        A 2D array containing land use data.\n",
    "    haz_crs : int, optional\n",
    "        The CRS of `hazard`. Default is EPSG:3035.\n",
    "    lu_crs : int, optional\n",
    "        The CRS of `landuse`. Default is EPSG:3035.\n",
    "    resolution : float, optional\n",
    "        The desired resolution in meters for both `hazard` and `landuse` after reprojection. Default is 100.\n",
    "    hazard_col : list, optional\n",
    "        A list of column names or indices for the hazard variable. Default is ['FX'].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple containing two xarray.DataArray objects:\n",
    "            - The land use variable with matching resolution and dimensions to the hazard variable.\n",
    "            - The hazard variable clipped to the extent of the land use variable, with matching resolution and dimensions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the crs of the hazard variable to haz_crs\n",
    "    hazard.rio.write_crs(haz_crs, inplace=True)\n",
    "\n",
    "    # Set the x and y dimensions in the hazard variable to 'x' and 'y' respectively\n",
    "    hazard.rio.set_spatial_dims(x_dim=\"x\",y_dim=\"y\", inplace=True)\n",
    "\n",
    "    # Reproject the landuse variable from EPSG:4326 to EPSG:3857\n",
    "    landuse = CLC_region.rio.reproject(\"EPSG:3857\",resolution=resolution)\n",
    "\n",
    "    # Get the minimum longitude and latitude values in the landuse variable\n",
    "    min_lon = landuse.x.min().to_dict()['data']\n",
    "    min_lat = landuse.y.min().to_dict()['data']\n",
    "\n",
    "    # Get the maximum longitude and latitude values in the landuse variable\n",
    "    max_lon = landuse.x.max().to_dict()['data']\n",
    "    max_lat = landuse.y.max().to_dict()['data']\n",
    "\n",
    "    # Create a bounding box using the minimum and maximum latitude and longitude values\n",
    "    area = gpd.GeoDataFrame([shapely.box(min_lon,min_lat,max_lon, max_lat)],columns=['geometry'])\n",
    "\n",
    "    # Set the crs of the bounding box to EPSG:3857\n",
    "    area.crs = 'epsg:3857'\n",
    "\n",
    "    # Convert the crs of the bounding box to EPSG:4326\n",
    "    area = area.to_crs(f'epsg:{haz_crs}')\n",
    "\n",
    "    # Clip the hazard variable to the extent of the bounding box\n",
    "    hazard = hazard.rio.clip(area.geometry.values, area.crs)\n",
    "\n",
    "    # Reproject the hazard variable to EPSG:3857 with the desired resolution\n",
    "    hazard = hazard.rio.reproject(\"EPSG:3857\",resolution=resolution)\n",
    "\n",
    "    # Clip the hazard variable again to the extent of the bounding box\n",
    "    hazard = hazard.rio.clip(area.geometry.values, area.crs)\n",
    "\n",
    "    # If the hazard variable has fewer columns and rows than the landuse variable, reproject the landuse variable to match the hazard variable\n",
    "    if (len(hazard.x)<len(landuse.x)) & (len(hazard.y)<len(landuse.y)):\n",
    "        landuse= landuse.rio.reproject_match(hazard)\n",
    "\n",
    "    # If the hazard variable has more columns and rows than the landuse variable, reproject the hazard variable to match the landuse variable\n",
    "    elif (len(hazard.x)>len(landuse.x)) & (len(hazard.y)>len(landuse.y)):\n",
    "        hazard = hazard.rio.reproject_match(landuse)\n",
    "\n",
    "    # return the new landuse and hazard map\n",
    "    return landuse,hazard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9ccb0d-2644-45ea-b435-79d83cd12a8e",
   "metadata": {
    "id": "Vkf6YKPZ-g4I"
   },
   "source": [
    "Now let's run the `match_rasters` function and let it do its magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3409f-5c41-4ffa-b881-fa166eec2521",
   "metadata": {
    "id": "v8NW3c1Q-g4I"
   },
   "outputs": [],
   "source": [
    "CLC_region_wind, windstorm = match_rasters(windstorm_europe,\n",
    "                                           CLC_region,\n",
    "                                           haz_crs=3035,\n",
    "                                           lu_crs=3035,\n",
    "                                           resolution=100,\n",
    "                                           hazard_col=['FX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2fdc04-2327-47d2-b43a-521dc95b6882",
   "metadata": {
    "id": "GgcwJe_6nJip"
   },
   "source": [
    "And let's have a look if the two rasters are now the same extend:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca69a83-350b-4d0e-adea-d6a00b9dfc38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "vzMbkiSLldlQ",
    "outputId": "6e73f8b1-33ad-4a7c-b95c-d320b6c75439"
   },
   "outputs": [],
   "source": [
    "CLC_region_wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0216bd-6497-4a0a-8903-31d46599a854",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "DXnxCBS_ldWg",
    "outputId": "ec49b756-0fd9-4d49-f9ff-9f68a52bf83c"
   },
   "outputs": [],
   "source": [
    "windstorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f3a8c5-aac5-4def-b79f-8e20be1cc822",
   "metadata": {
    "id": "6123eX9C-g4J"
   },
   "source": [
    "It worked! And to double check, let's also plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58536a6a-6e5b-40cd-8d14-dc453d781405",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "Aeay_slW-g4J",
    "outputId": "11424ad3-2a00-49db-db13-b4db8e73671e"
   },
   "outputs": [],
   "source": [
    "windstorm.FX.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e445352-2695-4d54-9abe-e3215817f355",
   "metadata": {
    "id": "JlZF-cs4gSuu"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 11:</b>  Describe the various steps you have taken to make sure that the windstorm map is now exactly the same extent as the corine land cover map. Feel free to include lines of code in your answer and also describe the different functions you have used along the way.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4959f306-df08-4548-8470-9083c814b203",
   "metadata": {
    "id": "LW158xPh-g4J"
   },
   "source": [
    "Now its finally time to do our damage assessment! To do so, we need to convert our data to `numpy.arrays()` to do our calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f82a7c-f2b1-43dd-bcb6-4a9d24738d75",
   "metadata": {
    "id": "QZIzWIeP-g4J"
   },
   "outputs": [],
   "source": [
    "landuse_map = CLC_region_wind['band_data'].to_numpy()[0,:,:]\n",
    "wind_map = windstorm['FX'].to_numpy()[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d83a65-c63b-427b-b950-2f4674fe8b82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aBqqRqbkmA1Y",
    "outputId": "709d6c91-4ad9-4e27-e6a9-e6201df32dc7"
   },
   "outputs": [],
   "source": [
    "wind_map.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca9bbe2-95f2-4b0d-9fb7-bb0ffc94ecef",
   "metadata": {
    "id": "J9QHyhSU-g4J"
   },
   "source": [
    "And remember that our windstorm data was stored in **m/s**. Hence, we need to convert it to **km/h**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ddca33-7360-4efb-84f2-7613fd360ca3",
   "metadata": {
    "id": "GqdUCXD_-g4J"
   },
   "outputs": [],
   "source": [
    "wind_map_kmh = wind_map*XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5ac7e-e817-49e2-b588-614e997adf8a",
   "metadata": {
    "id": "ln7NqRB1-g4J"
   },
   "source": [
    "And now let's run the DamageScanner to obtain the damage results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31da4031-fdd4-485f-af99-30fa49fdabe0",
   "metadata": {
    "id": "y_g0pj1h-g4J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "wind_damage_CLC = DamageScanner(landuse_map,wind_map_kmh,wind_curves,maxdam)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717a4a2-8d6b-436b-b855-bebc7835d0b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-6DbFD_JeFA1",
    "outputId": "fb251350-8885-4dde-e665-893fa04cde6e"
   },
   "outputs": [],
   "source": [
    "wind_damage_CLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c4ad75-a555-414d-bb64-6af5f10a2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! @TASK: Let students also perform risk assessment based on rasterized OSM land use data?? Code needs to be written for that. Or think about a really good question that we can ask here about this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d46699-d759-48e3-a5ef-09d45ec8e41a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28e483d0-06b1-432f-86e6-d7a68e9811a4",
   "metadata": {},
   "source": [
    "## 6. Extracting high-resolution data from OpenStreetMap\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b596d-ad9f-4e42-bc2f-e889d216f0e7",
   "metadata": {},
   "source": [
    "### Extracting buildings from OpenStreetMap\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f42ba03-9c17-465d-97eb-77df502dd8ee",
   "metadata": {
    "id": "WMOSa6JF47DS"
   },
   "source": [
    "There is a lot more data to extract from OpenStreetMap besides land-use information. Let's extract some building data. To do so, we use the *\"building\"* tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f86ddc-ce27-4753-9e70-af6df03d7850",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\"building\": True}\n",
    "buildings = ox.features_from_place(place_name, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772d95a6-c2ce-48a6-a7d0-bc1f4b77c323",
   "metadata": {},
   "source": [
    "In case the above does not work, you can continue the assignment by using the code below (make sure you remove the hashtags to run it). If you decide to use the data as specified below, also change the map at the start to 'Kampen'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a7e508a-b20a-416c-8f2a-c8dd36a60389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote_url = https://github.com/VU-IVM/UNIGIS_ProgrammingGIS/tree/main/TAA2'\n",
    "# file = 'kampen_buildings.gpkg'\n",
    "#  \n",
    "# #request.urlretrieve(remote_url, file)\n",
    "# buildings = gpd.GeoDataFrame.from_file('kampen_buildings.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e45bdb-36a3-4efd-b0e4-111f5fd858fe",
   "metadata": {
    "id": "bon7osXA47DT"
   },
   "source": [
    "Now let's see what information is actually extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a60806-c927-4d0c-ab04-dc07c9c7a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7f7ff1-ed38-4dca-b2ad-f09472566879",
   "metadata": {
    "id": "p8dhZx1n47DT"
   },
   "source": [
    "As you notice in the output of the cell above, there are many columns which just contain \"NaN\". And there even seem to be to many columns to even visualize properly in one view.\n",
    "\n",
    "Let's check what information is collected for the different buildings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b1253-16b0-4513-8903-966b1816715f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1675087861529,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "W3ZpsIkO47DT",
    "outputId": "385616f8-25fe-4675-f5f0-16d7fa9b0df7"
   },
   "outputs": [],
   "source": [
    "buildings.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772be8a9-7ab6-4996-9311-e165fcc6c8ed",
   "metadata": {
    "id": "sH7NTKENA4WO"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 12:</b>  Let's have a look at the extracted building information. Please describe in your own words the information it contains. Is there specific information that suprises you to see, and do you think anything is missing that you expected? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7077034-4cfe-436a-b5b2-64fc77f24ae5",
   "metadata": {
    "id": "Z37JRRc747DT"
   },
   "source": [
    "One interesting column is called `start_date`. This shows the building year per building. \n",
    "\n",
    "Let's explore this year of building a bit more.\n",
    "\n",
    "First, it would be interesting to get an idea how many buildings are build in each year through using the `value_counts()` function. Normally, that functions ranks the values in descending order (high to low). We are more interested in how this has developed over time. So we use the `sort_index()` function to sort the values by year. Add these two functions in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c9a71-68b4-4adc-a1b4-52ff94275a6f",
   "metadata": {
    "executionInfo": {
     "elapsed": 924,
     "status": "ok",
     "timestamp": 1675087884735,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "lNSe826i47DT"
   },
   "outputs": [],
   "source": [
    "building_year = buildings.start_date. XXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e9c436-fd01-46f7-8f73-44eccafe7816",
   "metadata": {
    "id": "X6b_T5xs47DU"
   },
   "source": [
    "There is not better way to further explore this years than through plotting it. Don't forget to add things such as a x label, y label and title. Have a look at some of the matplotlib [tutorials](https://matplotlib.org/stable/tutorials/introductory/quick_start.html). Note that you need to look at the code that also uses subplots and where they use the `ax` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6ee4b-f664-4955-9781-86d56920b3e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1636,
     "status": "ok",
     "timestamp": 1675087889714,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "fmk6m78I47DU",
    "outputId": "78f3ea6a-284d-495f-b596-12db32305128"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(5,18))\n",
    "\n",
    "building_year.plot(kind='barh',ax=ax)\n",
    "\n",
    "ax.tick_params(axis='y', which='major', labelsize=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5ce5b6-f7b6-47a4-b4b7-2cac7cc933bf",
   "metadata": {
    "id": "AwRyhvNeBn0G"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 13:</b>  Please upload a figure that shows the development of building stock over the years in your region of interest. Make sure it contains all the necessary elements (labels on the axis, title, etc.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f6011-87fd-464a-ad8b-52ad810d8b75",
   "metadata": {
    "id": "wrcM1p-m47DU"
   },
   "source": [
    "What we also noticed is that quite some buildings are identified as 'yes'. This is not very useful as it does not really say much about the use of the building. \n",
    "\n",
    "Let's see for how many buildings this is the case: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca163a97-54bd-4050-bea6-2721d024a1eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1675087945407,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "_4eKR2Bo47DU",
    "outputId": "54e29c44-9717-4eee-984f-9555659317be"
   },
   "outputs": [],
   "source": [
    "buildings.building.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502fcb4a-cc93-46fa-bc1a-5dad7f4438bc",
   "metadata": {},
   "source": [
    "As you have seen from the `value_counts` function, there are quite a few buildings with only very few tags. You could either consider to not include them in your plot at all (for example by using the `isin` function or the `query` function, see also [here](https://stackoverflow.com/questions/12096252/use-a-list-of-values-to-select-rows-from-a-pandas-dataframe)), or rename them, similar to how you named the natural land cover classes for the land-use map. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22598d8d-a73c-41b7-befd-f8abafc86162",
   "metadata": {
    "id": "vF6WJ9_k47DU"
   },
   "source": [
    "Now let's visualize the buildings again. We need to create a similar color dictionary as we did for the land-use categories. Now its up to you to make it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a2389-8302-4e4f-8624-2beb0225ecfd",
   "metadata": {
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1675087956546,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "RYRxKXxd47DU"
   },
   "outputs": [],
   "source": [
    "color_dict = { 'yes' : \"#f1134b\", \n",
    "              'house':'#f13013', \n",
    "              'industrial':'#0f045c',\n",
    "              'farm':'#fcfcb9', \n",
    "              'bungalow':'#f13013',\n",
    "              'service':'#CB8DDB' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54672469-3961-4b67-860e-17f9320d1a62",
   "metadata": {
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1675087958726,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "YjRwC-K-47DU"
   },
   "outputs": [],
   "source": [
    "# Remove multiple keys from dictionary\n",
    "color_dict = {key: color_dict[key]\n",
    "             for key in color_dict if key not in  list(set(color_dict)-set(buildings.building.unique()))}\n",
    "\n",
    "map_dict = dict(zip(color_dict.keys(),[x for x in range(len(color_dict))]))\n",
    "buildings['col_landuse'] =buildings.building.apply(lambda x: color_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbaef6d-6b28-45f4-ace9-6a5c9dec0f2f",
   "metadata": {
    "id": "wGh7rbnB47DU"
   },
   "source": [
    "And plot the figure in the same manner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad1b9f-855a-468e-9090-25d7ace2990d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "executionInfo": {
     "elapsed": 3651,
     "status": "ok",
     "timestamp": 1675087966347,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "oDfamvIV47DV",
    "outputId": "dbcee552-e955-4d2b-ddda-909ab4265105"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(12,10))\n",
    "\n",
    "# add color scheme\n",
    "color_scheme_map = list(color_dict.values())\n",
    "cmap = LinearSegmentedColormap.from_list(name='landuse',\n",
    "                                     colors=color_scheme_map)  \n",
    "\n",
    "# and plot the land-use map.\n",
    "buildings.plot(color=buildings['col_landuse'],ax=ax,linewidth=0)\n",
    "\n",
    "# remove the ax labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_axis_off()\n",
    "\n",
    "# add a legend:\n",
    "legend_elements = []\n",
    "for iter_,item in enumerate(color_dict):\n",
    "    legend_elements.append(Patch(facecolor=color_scheme_map[iter_],label=item))        \n",
    "\n",
    "ax.legend(handles=legend_elements,edgecolor='black',facecolor='#fefdfd',prop={'size':12},loc=(1.02,0.2)) \n",
    "\n",
    "# add a title\n",
    "ax.set_title(place_name,fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc1437d-8deb-4569-a3ee-9270676f0e41",
   "metadata": {
    "id": "IJalDDJvB6Yd"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 14:</b>  Please upload a figure of your building stock map of your region of interest. Make sure that the interpretation is clear. If necessary, merge multiple categories into one (i.e., when some categories only contain 1 or 2 buildings).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59fa9dc-68f1-4d39-8adc-f917a0af3a04",
   "metadata": {},
   "source": [
    "### Extracting roads from OpenStreetMap\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb8f23-6b4e-47ce-a1df-12ca10e90897",
   "metadata": {
    "id": "HpWnKfIk47DV"
   },
   "source": [
    "Let's continue (and end) this tutorial with the core data in OpenStreetMap (it is even in the name): roads!\n",
    "\n",
    "Now, instead of using tags, we want to identify what type of roads we would like to extract. Let's first only extract roads that can be used to drive.\n",
    "\n",
    "The `graph_from_place()` function returns a `NetworkX` Graph element. You can read more about these graph elements in the introduction page of [NetworkX](https://networkx.org/documentation/stable/reference/introduction.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73036bbd-08b1-4d2d-bc14-9efd48d4ec76",
   "metadata": {
    "executionInfo": {
     "elapsed": 13403,
     "status": "ok",
     "timestamp": 1675088179196,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "MpjxUadp47DV"
   },
   "outputs": [],
   "source": [
    "G = ox.graph_from_place(place_name, network_type=\"drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1596cb-9a1b-4a67-87cd-cee4f687ad11",
   "metadata": {
    "id": "NA_HAmHx47DV"
   },
   "source": [
    "Unfortunately, it is  bit difficult to easily view all the roads within such a Graph element. To be able to explore the data, we are going to convert it to a `Geopandas GeoDataFrame`, using the `to_pandas_edgelist()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b52effc-4eaf-44b5-b031-2481d2125197",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1675088179197,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "4dMXZb_v47DV",
    "outputId": "e615d5f8-6b96-4a32-f114-ce38b1481b70"
   },
   "outputs": [],
   "source": [
    "roads = gpd.GeoDataFrame(nx.to_pandas_edgelist(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a191c-0d36-4bb5-8ed7-4f12bb05e1f5",
   "metadata": {
    "id": "yds5NBlF47DV"
   },
   "source": [
    "In some cases, roads are classified with more than one category. If that is the case, they are captured within a `list`. To overcome this issue, we specify that we want the entire `highway` column as a `string` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f76461-aac1-4534-8a97-2abc841107b4",
   "metadata": {
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1675088191403,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "NxTg1jb847DV"
   },
   "outputs": [],
   "source": [
    "roads.highway = roads.highway.astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5080124a-c7f4-45f6-aced-a27f8793ef59",
   "metadata": {
    "id": "rbzl5JPR47DW"
   },
   "source": [
    "Now we can create a plot to see how the road network is configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c2f581-4182-471e-823b-0280181494e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "executionInfo": {
     "elapsed": 888,
     "status": "ok",
     "timestamp": 1675088196301,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "uyo3Ggpc47DW",
    "outputId": "e58c915a-b085-498c-e7ea-8d62f237d417"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(12,10))\n",
    "\n",
    "\n",
    "roads.plot(column='highway',legend=True,ax=ax,legend_kwds={'loc': 'lower right'});\n",
    "\n",
    "\n",
    "# remove the ax labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a98a1c-e8d3-4f84-80df-5e8577a3458b",
   "metadata": {
    "id": "M18fuTWM47DW",
    "tags": []
   },
   "source": [
    "It would also be interesting to explore the network a little but more interactively. **OSMnx** has a function called `plot_graph_folium()`, which allow us to use the [folium](https://python-visualization.github.io/folium/quickstart.html#Getting-Started) package to plot data interactively on a map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7ab55-f4ce-4706-83a0-5b944c2bfd7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866
    },
    "executionInfo": {
     "elapsed": 1720,
     "status": "ok",
     "timestamp": 1675088204394,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "lpWHR0Ez47DW",
    "outputId": "38be3bea-b399-4e8f-a081-210baa559ef7"
   },
   "outputs": [],
   "source": [
    "m1 = ox.plot_graph_folium(G, popup_attribute=\"highway\", weight=2, color=\"#8b0000\")\n",
    "m1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "274d172a-62df-4095-987d-1de387104e8d",
   "metadata": {
    "id": "gm8NIAR947DW"
   },
   "source": [
    "One of the exiting things we can do with this data is that we can compute and plot routes between two points on a map.\n",
    "\n",
    "Let's first select two random start and end points from the graph and compute the shortest route between them through using the `shortest_path()` function of the `NetworkX` package.\n",
    "\n",
    "The function  `ox.nearest_nodes()` looks for the nearest point in your network based on a `X` and `Y` coordinate. For example, in the code below, the origin node is based on the northwestern corner of your bounding box, whereas the destination node is based on the coordinates of the southeastern corner of your bounding box.   \n",
    "\n",
    "So this can also be rewritten as:\n",
    "\n",
    "```\n",
    "origin_node = ox.nearest_nodes(G,4.65465, 56.6778) \n",
    "destination_node = ox.nearest_nodes(G,4.61055, 59.5487) \n",
    "route = nx.shortest_path(G, origin_node, destination_node) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d7552-5ec6-42f0-90a7-7e70b5c435ca",
   "metadata": {
    "id": "Zi_xhqXTCi3h"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 15:</b>  The last element of this tutorial is to play around with routing. Please explain in your own words what the .shortest_path() algorithm does. Include the term 'Dijkstra algorithm' in your answer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e7faf0-43f4-4947-a5b7-0d5f2c1632ea",
   "metadata": {
    "executionInfo": {
     "elapsed": 837,
     "status": "ok",
     "timestamp": 1675088236066,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "Dr7Ftbbh47DW"
   },
   "outputs": [],
   "source": [
    "origin_node = ox.nearest_nodes(G,area['bbox_west'].values[0], area['bbox_north'].values[0])\n",
    "destination_node = ox.nearest_nodes(G,area['bbox_east'].values[0], area['bbox_south'].values[0])\n",
    "route = nx.shortest_path(G, origin_node, destination_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3724e1e-0cfa-4e7c-8d94-1d76e10c06d1",
   "metadata": {
    "id": "4UuCS8G247DW"
   },
   "source": [
    "We can plot the route with folium. Like above, you can pass keyword args along to folium PolyLine to style the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7785a7-c4c3-491b-8c65-44353cdddc43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866
    },
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1675088397348,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "7QrZ6Gpi47DX",
    "outputId": "33fecead-a6d7-4090-99da-e09d0c34081a"
   },
   "outputs": [],
   "source": [
    "m2 = ox.plot_route_folium(G, route, weight=10)\n",
    "m2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df6de86-02e3-4a06-b99f-ec39c71385e8",
   "metadata": {
    "id": "eedHqPli47DX"
   },
   "source": [
    "Plot the route with folium on top of the previously created map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0813cf0-0fb3-4ba7-9012-dc5c3f362743",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866
    },
    "executionInfo": {
     "elapsed": 2518,
     "status": "ok",
     "timestamp": 1675088413924,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "aHzxZAbZ47DX",
    "outputId": "01ee7d97-4792-41fb-925c-c44fb9b15a3f"
   },
   "outputs": [],
   "source": [
    "m3 = ox.plot_route_folium(G, route, route_map=m1, popup_attribute=\"name\", weight=7)\n",
    "m3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0eda49e-6b12-42b9-b88d-ba0938f2f507",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 16:</b>  Please add one more routes on a map and upload the resulting figure here.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508022f5-46d7-4c69-91d2-46711d6a514c",
   "metadata": {},
   "source": [
    "## 7. Perform a damage assessment of the road network using OpenStreetMap\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7623d-40ee-4262-9781-0c2ed3ea1889",
   "metadata": {
    "id": "bKFmTKpj-g4K"
   },
   "source": [
    "Generally, wind damage does not cause much damage to roads. There will be clean-up cost of the trees that will fall on the roads, but structural damage is rare. As such, we will only do a flood damage assessment for the road network of our region.\n",
    "\n",
    "To do so, we first need to extract the roads again. We will use the `graph_from_place()` function again to do so. However, the area will be to large to extract roads, so we will focus our analysis on the main network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abacf8e1-b27c-4156-8521-87f38004ac2e",
   "metadata": {
    "id": "CUqFG7AD-g4K"
   },
   "outputs": [],
   "source": [
    "cf = '[\"highway\"~\"trunk|motorway|primary|secondary\"]'\n",
    "G = ox.graph_from_place(place_name, network_type=\"drive\", custom_filter=cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de9a96-e3fc-4ab5-b090-be6412a0d0a1",
   "metadata": {
    "id": "modIJTEz-g4K"
   },
   "source": [
    "Now we convert the road network to a `geodataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90acac15-3b1e-4c0a-b0a4-6033d243f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads = gpd.GeoDataFrame(nx.to_pandas_edgelist(G))\n",
    "roads.highway = roads.highway.astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f95cc0-2611-472f-92fa-c256f368c33c",
   "metadata": {},
   "source": [
    "In case the above does not work, you can continue the assignment by using the code below (make sure you remove the hashtags to run it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55752d12-81de-4eb5-b849-90473f88478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from urllib import request\n",
    "# remote_url = 'https://github.com/VU-IVM/UNIGIS_ProgrammingGIS/tree/main/TAA2'\n",
    "# file = 'kampen_roads.gpkg'\n",
    "#  \n",
    "# #request.urlretrieve(remote_url, file)\n",
    "# roads = gpd.GeoDataFrame.from_file('kampen_roads.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4a201-87b1-4cd8-a206-6b965c9b4107",
   "metadata": {
    "id": "VIaMGLxA-g4K"
   },
   "source": [
    "And lets have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a864f8-6af7-454f-869c-197e5e47151b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "dx_299FS-g4L",
    "outputId": "ffdab479-6a25-4794-da3a-cbacf2accaa4"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(12,10))\n",
    "\n",
    "\n",
    "roads.plot(column='highway',legend=True,ax=ax,legend_kwds={'loc': 'lower right'});\n",
    "\n",
    "\n",
    "# remove the ax labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789ae59-e6c9-4a1c-a1ad-44e94c9172ca",
   "metadata": {
    "id": "PSGo7dC3-g4L"
   },
   "source": [
    "It is actually quite inconvenient to have all these lists in the data for when we want to do the damage assessment. Let's clean this up a bit. To do so, we first make sure that all the lists are represented as actual lists, and not lists wrapped within a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c4746a-6efd-4b59-8b6b-5fe9a8c42372",
   "metadata": {
    "id": "S_LZSRI6-g4L"
   },
   "outputs": [],
   "source": [
    "roads.highway = roads.highway.apply(lambda x: x.strip('][').split(', '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb311b10-0a1c-4e0a-ad1f-cef37aa40ad7",
   "metadata": {
    "id": "cwQKiRDd-g4L"
   },
   "source": [
    "Now we just need to grab the first element of each of the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e449847-c279-479e-bf3b-382b8c50e018",
   "metadata": {
    "id": "qe86tcET-g4L"
   },
   "outputs": [],
   "source": [
    "roads.highway = roads.highway.apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "roads.highway = roads.highway.str.replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f95ad-9a1f-43e1-b098-45255c9d5dd2",
   "metadata": {
    "id": "TkyDDDIP-g4L"
   },
   "source": [
    "And let's have a look whether this worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc3a62-c266-4d0e-bd03-ad1d1b4b22e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "f5qPSBmq-g4L",
    "outputId": "6ac152f2-14f1-4e6c-c53a-9d68db347ce6"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(12,10))\n",
    "\n",
    "roads.plot(column='highway',legend=True,ax=ax,legend_kwds={'loc': 'upper left','ncol':1});\n",
    "\n",
    "# remove the ax labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3049d42-da1f-4dc2-a56f-1ce6b3080fd0",
   "metadata": {
    "id": "u0crazq8iQjQ"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 17:</b> Upload a figure of the cleaned road network (e.g. in which you do not see any of the listed road types anymore)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d784f6dc-7091-4e60-b7df-58682efb66ef",
   "metadata": {
    "id": "J63sExRp-g4L"
   },
   "source": [
    "Nice! now let's start with the damage calculation. As you already have may have noticed, our data is now not stored in raster format, but in vector format. One way to deal with this issue is to convert our vector data to raster data, but we will lose a lot of information and detail. As such, we will perform the damage assessment on the road elements, using the xarray flood map.\n",
    "\n",
    "Let's start with preparing the flood data into vector format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68dc43-fd65-416c-bc7a-a1b1231187d3",
   "metadata": {
    "id": "uHmaZFXV-g4L"
   },
   "outputs": [],
   "source": [
    "# get the mean values\n",
    "flood_map_vector = flood_map_area['band_data'].to_dataframe().reset_index()\n",
    "\n",
    "# create geometry values and drop lat lon columns\n",
    "flood_map_vector['geometry'] = [shapely.points(x) for x in list(zip(flood_map_vector['x'],flood_map_vector['y']))]\n",
    "flood_map_vector = flood_map_vector.drop(['x','y','band','spatial_ref'],axis=1)\n",
    "\n",
    "# drop all non values to reduce size\n",
    "flood_map_vector = flood_map_vector.loc[~flood_map_vector['band_data'].isna()].reset_index(drop=True)\n",
    "\n",
    "# and turn them into squares again:\n",
    "flood_map_vector.geometry= shapely.buffer(flood_map_vector.geometry,distance=100/2,cap_style='square').values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9894f1ba-e637-4ede-b46c-5aa4747eaea0",
   "metadata": {
    "id": "sKb-ig4Q-g4M"
   },
   "source": [
    "And let's plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ab83a-62af-4142-bb26-157e077d868b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "LL3YU6r1-g4M",
    "outputId": "e0a9e61f-e376-436c-a11a-fa58651bf15a"
   },
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame(flood_map_vector.copy()).plot(column='band_data',cmap='Blues',vmax=5,linewidth=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdbc0d8-beba-4b37-be49-f5226953f19b",
   "metadata": {
    "id": "XBsxnhjN-g4M"
   },
   "source": [
    "We will need a bunch of functions to make sure we can do our calculations. They are specified below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470c747-42aa-4f20-bbf3-90773c3d4cc8",
   "metadata": {
    "id": "T-XfgGLB-g4M"
   },
   "outputs": [],
   "source": [
    "def reproject(df_ds,current_crs=\"epsg:4326\",approximate_crs = \"epsg:3035\"):\n",
    "    geometries = df_ds['geometry']\n",
    "    coords = shapely.get_coordinates(geometries)\n",
    "    transformer=pyproj.Transformer.from_crs(current_crs, approximate_crs,always_xy=True)\n",
    "    new_coords = transformer.transform(coords[:, 0], coords[:, 1])\n",
    "    \n",
    "    return shapely.set_coordinates(geometries.copy(), np.array(new_coords).T) \n",
    "\n",
    "def buffer_assets(assets,buffer_size=100):\n",
    "    assets['buffered'] = shapely.buffer(assets.geometry.values,buffer_size)\n",
    "    return assets\n",
    "\n",
    "def overlay_hazard_assets(df_ds,assets):\n",
    "\n",
    "    #overlay \n",
    "    hazard_tree = shapely.STRtree(df_ds.geometry.values)\n",
    "    if (shapely.get_type_id(assets.iloc[0].geometry) == 3) | (shapely.get_type_id(assets.iloc[0].geometry) == 6):\n",
    "        return  hazard_tree.query(assets.geometry,predicate='intersects')    \n",
    "    else:\n",
    "        return  hazard_tree.query(assets.buffered,predicate='intersects')\n",
    "    \n",
    "def get_damage_per_asset(asset,df_ds,assets):\n",
    "    # find the exact hazard overlays:\n",
    "    get_hazard_points = df_ds.iloc[asset[1]['hazard_point'].values].reset_index()\n",
    "    get_hazard_points = get_hazard_points.loc[shapely.intersects(get_hazard_points.geometry.values,assets.iloc[asset[0]].geometry)]\n",
    "\n",
    "    asset_geom = assets.iloc[asset[0]].geometry\n",
    "\n",
    "    maxdam_asset = 100\n",
    "    hazard_intensity = np.arange(0,10,0.1) \n",
    "    fragility_values = np.arange(0,1,0.01) \n",
    "        \n",
    "    if len(get_hazard_points) == 0:\n",
    "        return asset[0],0\n",
    "    else:\n",
    "        get_hazard_points['overlay_meters'] = shapely.length(shapely.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "        return asset[0],np.sum((np.interp(get_hazard_points.band_data.values,hazard_intensity,fragility_values))*get_hazard_points.overlay_meters*maxdam_asset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a243c-dd99-44c1-975c-7cb4eab99359",
   "metadata": {
    "id": "og2Bkcv--g4M"
   },
   "source": [
    "Now we need to make sure that the road data is the same coordinate system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c68a5-90ae-4394-9e4f-4ed5ba0c665d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NvtDuspN-g4M",
    "outputId": "8d920938-ab07-42f9-bb88-34483e751c3f"
   },
   "outputs": [],
   "source": [
    "roads.geometry = reproject(roads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efebb735-7955-4a75-bedf-1b213067fe20",
   "metadata": {
    "id": "4JT25WTv-g4M"
   },
   "source": [
    "And we can now overlay the roads with the flood data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de298f-9e06-40c3-b3a2-eecf2aa7205d",
   "metadata": {
    "id": "8rtBYbX_-g4M"
   },
   "outputs": [],
   "source": [
    "overlay_roads = pd.DataFrame(overlay_hazard_assets(flood_map_vector,buffer_assets(roads)).T,columns=['asset','hazard_point'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aeaec5-4ea3-48a5-93b5-109a1578c77e",
   "metadata": {
    "id": "s82DyD_y-g4M"
   },
   "source": [
    "And estimate the damages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa56503-90e8-4b7f-a5dc-82a4b235e95b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGqPFklh-g4N",
    "outputId": "207937c9-dcc5-41a5-ebc4-76aa03003022"
   },
   "outputs": [],
   "source": [
    "collect_output = []\n",
    "for asset in tqdm(overlay_roads.groupby('asset'),total=len(overlay_roads.asset.unique()),\n",
    "                              desc='polyline damage calculation for'):\n",
    "    collect_output.append(get_damage_per_asset(asset,flood_map_vector,roads))\n",
    "    \n",
    "damaged_roads = roads.merge(pd.DataFrame(collect_output,columns=['index','damage']),\n",
    "                                                          left_index=True,right_on='index')[['highway','geometry','damage']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580663ca-b83f-4724-a699-b6a4790678ad",
   "metadata": {
    "id": "RFGZxWl7i7pQ"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 18:</b> Describe the various steps we have taken to perform the damage assessment on the road network. How is this approach different compared to the raster-based approach? Highlight the differences you find most important. Include any line of code you may want to include to make your story clear.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e42c7f3-c868-400c-858e-7ac0c848fd4c",
   "metadata": {
    "id": "B5jpsbyC-g4N"
   },
   "source": [
    "And let's plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef910b4e-201e-444b-92b6-826be82a5164",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "n25j-3wG-g4N",
    "outputId": "b926a8e7-7e51-4434-f3b8-d61e6278bc24"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(12,10))\n",
    "\n",
    "damaged_roads.plot(column='damage',cmap='Reds',ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d5033f-ac25-4ae1-9991-ca0899c1b8d4",
   "metadata": {
    "id": "bTfmvwW2jchB"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 19:</b> Describe the most severely damaged parts of the road network. Use Google Maps to identify these roads. Are you surprised by the results?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92fb12-9049-4e15-8992-b3d0cbd459b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

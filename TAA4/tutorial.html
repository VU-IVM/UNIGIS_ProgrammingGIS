

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>TAA4: Unsupervised learning &#8212; UNIGIS - Big Data in Sustainability Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'TAA4/tutorial';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="TAA5: Accessibility to healthcare facilities" href="../TAA5/tutorial.html" />
    <link rel="prev" title="Lecture: Loading API geodata and clustering" href="lecture.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="UNIGIS - Big Data in Sustainability Science - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="UNIGIS - Big Data in Sustainability Science - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Course overview</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../course_basics/course_intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../course_basics/teachers.html">Teachers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../course_basics/schedule.html">Course schedule</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">TAA1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../TAA1/tutorial1.html">Tutorial 1: Introduction to Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TAA1/tutorial2.html">Tutorial 2: Introduction to NumPy and Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TAA1/tutorial3.html">Tutorial 3: Introduction to Data Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TAA1/tutorial4.html">Tutorial 4: Introduction to GeoPandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TAA1/tutorial5.html">Tutorial 5: Introduction to Rasterio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TAA1/tutorial6.html">Tutorial 6: Introduction to Xarray</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TAA1/tutorial7.html">Tutorial 7: Introduction to Rioxarray</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">TAA2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../TAA2/lecture.html">Lecture: Big Data in the public domain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TAA2/tutorial.html">TAA2: Natural Hazard Risk Assessment using Open Data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">TAA3</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../TAA3/lecture.html">Lecture: Introduction to Statistical Learning on Geospatial Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TAA3/tutorial.html">TAA3: Crop cover classification</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">TAA4</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture.html">Lecture: Loading API geodata and clustering</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">TAA4: Unsupervised learning</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">TAA5</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../TAA5/tutorial.html">TAA5: Accessibility to healthcare facilities</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/VU-IVM/UNIGIS_ProgrammingGIS/blob/main/TAA4/tutorial.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/VU-IVM/UNIGIS_ProgrammingGIS" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/VU-IVM/UNIGIS_ProgrammingGIS/issues/new?title=Issue%20on%20page%20%2FTAA4/tutorial.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/TAA4/tutorial.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>TAA4: Unsupervised learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">TAA4: Unsupervised learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#important-before-we-start">Important before we start</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#packages">Packages</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-preparation">Dataset preparation</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-data-for-the-randstad-area">Load data for the Randstad area</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handle-missing-data">Handle missing data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing">Visualizing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fix-non-ratio-d-columns">Fix non-ratio’d columns</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#normalizing"><strong>Normalizing</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering">Clustering</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-and-evaluating-k-means-clustering">Running and evaluating K-Means clustering</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis-of-clusters">Analysis of clusters</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#wrapping-up">Wrapping up</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-pca-to-reduce-dimensionality">Using PCA to reduce dimensionality</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#re-run-and-re-interpret">Re-run and re-interpret</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="taa4-unsupervised-learning">
<h1>TAA4: Unsupervised learning<a class="headerlink" href="#taa4-unsupervised-learning" title="Permalink to this heading">#</a></h1>
<p>In this tutorial we will work with 4-digit zipcode-level data from Dutch neighbourhoods to cluster them by similarity. In this tutorial you will learn about the nuances of data pre-processing for unsupervised learning, running and evaluating KMeans, and finally about interpreting the results of unsupervised learning.</p>
<section id="important-before-we-start">
<h2>Important before we start<a class="headerlink" href="#important-before-we-start" title="Permalink to this heading">#</a></h2>
<hr class="docutils" />
<p>This is a 1-week exercise rather than the 2-week exercises of the previous weeks. For that reason, it contains more pre-filled code. You will have the chance to experiment a little bit for some questions for those that find the coding too easy, though.</p>
<p><strong>❗Questions are indicated in full bold face.</strong> They should be filled in on Canvas, and we suggest explaining your rationale and thoughts, as they are intended to test your understanding of the ML pipeline.</p>
<p><strong>⚠️ Make sure that you copy this file</strong> before you continue, else you will lose everything. To do so, go to Bestand/File and click on Een kopie opslaan in Drive/Save a Copy on Drive!</p>
<p><strong>⚠️ Partial use of AI is allowed.</strong> You may use it to generate code, and to check your understanding of key concepts. HOWEVER, don’t use it to generate full answers to questions. We want to see questions written in your own words!</p>
</section>
<section id="learning-objectives">
<h2>Learning Objectives<a class="headerlink" href="#learning-objectives" title="Permalink to this heading">#</a></h2>
<hr><ul class="simple">
<li><p>Querying data from a Web Feature Service (WFS)</p></li>
<li><p>Understanding the nuances of data processing for unsupervised learning</p></li>
<li><p>Understanding metrics for unsupervised learning, as well as their downsides</p></li>
<li><p>Learning to post-hoc interpret cluster centroids</p></li>
</ul>
</section>
<section id="packages">
<h2>Packages<a class="headerlink" href="#packages" title="Permalink to this heading">#</a></h2>
<hr><p>The following packages are noteworthy in this tutorial:</p>
<p><a class="reference external" href="https://pandas.pydata.org/docs/"><strong>Pandas</strong></a> is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.</p>
<p><a class="reference external" href="https://geopandas.org/"><strong>GeoPandas</strong></a> is a Python package that extends the datatypes used by pandas to allow spatial operations on geometric types.</p>
<p><a class="reference external" href="https://matplotlib.org/"><strong>Matplotlib</strong></a> is a comprehensive Python package for creating static, animated, and interactive visualizations in Python. Matplotlib makes easy things easy and hard things possible.</p>
<p><a class="reference external" href="https://contextily.readthedocs.io/en/latest/"><strong>contextily</strong></a> Contextily provides one-line basemap loading for plotting in Python, which makes it much easier to add context to your visualized spatial data.</p>
<p><a class="reference external" href="https://owslib.readthedocs.io/en/latest/"><strong>owslib</strong></a> owslib is a package that wraps requests to spatial API endpoints, such as web feature services, making it easier to load spatial data from APIs.</p>
<p><a class="reference external" href="https://scikit-learn.org/stable/"><strong>scikit-learn</strong></a> is a Python package for statistical learning that is built on the general NumPy ecosystem. It is the most-used package for classical machine learning.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>contextily<span class="w"> </span>-q
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Built-ins</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>

<span class="c1"># Data wrangling</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">geopandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">gpd</span>

<span class="c1"># Visualization</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">contextily</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ctx</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="c1"># Analysis</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1"># Metrics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">davies_bouldin_score</span><span class="p">,</span> <span class="n">calinski_harabasz_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="dataset-preparation">
<h1>Dataset preparation<a class="headerlink" href="#dataset-preparation" title="Permalink to this heading">#</a></h1>
<p>In this tutorial we will load a dataset straight from an API, which as you will see comes with its own set of necessary pre-processing steps. We will first download the dataset, followed by some clean-up and lastly some pre-processing steps to prepare the data for clustering.</p>
<section id="load-data-for-the-randstad-area">
<h2>Load data for the Randstad area<a class="headerlink" href="#load-data-for-the-randstad-area" title="Permalink to this heading">#</a></h2>
<p>In order to find patterns in unstructured data, we of course first need data. For our example we will use neighbourhood-level statistics provided by the Central Burea for Statistics (CBS) Netherlands. The bounding box below is set to cover the Randstad area and Noord-Holland at the 4-digit zipcode level. The script below will query the Web Feature Service (WFS) and write a local copy so that we can then load it and analyze it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># WFS endpoint for CBS Postcode4 2023</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://service.pdok.nl/cbs/postcode4/2023/wfs/v1_0&quot;</span>

<span class="c1"># Bounding box in EPSG:28992</span>
<span class="n">bbox</span> <span class="o">=</span> <span class="p">(</span><span class="mi">76000</span><span class="p">,</span> <span class="mi">430000</span><span class="p">,</span> <span class="mi">162000</span><span class="p">,</span> <span class="mi">550000</span><span class="p">)</span>

<span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">service</span><span class="o">=</span><span class="s2">&quot;WFS&quot;</span><span class="p">,</span>
    <span class="n">version</span><span class="o">=</span><span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
    <span class="n">request</span><span class="o">=</span><span class="s2">&quot;GetFeature&quot;</span><span class="p">,</span>
    <span class="n">typeName</span><span class="o">=</span><span class="s2">&quot;postcode4:postcode4&quot;</span><span class="p">,</span>
    <span class="n">srsName</span><span class="o">=</span><span class="s2">&quot;EPSG:28992&quot;</span><span class="p">,</span>
    <span class="n">bbox</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">bbox</span><span class="p">))</span>    <span class="c1"># Add bounding box filter</span>
<span class="p">)</span>

<span class="c1"># Fetch raw response</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

<span class="c1"># Save to GML</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;zipcode4_data.gml&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>With the data written out to the virtual machine, we can load it and have a look at the table structure.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load into GeoPandas</span>
<span class="n">gdf</span> <span class="o">=</span> <span class="n">gpd</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="s2">&quot;zipcode4_data.gml&quot;</span><span class="p">)</span>
<span class="n">gdf</span><span class="o">.</span><span class="n">set_crs</span><span class="p">(</span><span class="n">epsg</span><span class="o">=</span><span class="mi">28992</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total number of rows: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">gdf</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">gdf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>As you can tell (maybe with the help of a translator), the dataset is comprised of a mix of demographic data, building data, distance data, and descriptive metadata about the zipcode area.</p>
</section>
<section id="handle-missing-data">
<h2>Handle missing data<a class="headerlink" href="#handle-missing-data" title="Permalink to this heading">#</a></h2>
<p>This dataset is a decent representation of what you can expect working with real-world data. It has no-data columns, as well as rows which had their values omitted for privacy reasons (e.g. in a small neighbourhood, certain demographic stats are hidden). Working with KMeans requires us to make very deliberate choices on how we handle these, as otherwise they might skew the model.</p>
<p>Let’s first have a look at the scale of the problem. The dataset marks no-data values as any values below zero (as everything is count or demographic data). Let’s first look at the columns with non-included data (code -99995). Write some code to find these columns. If you do it right, you should have 98 columns.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Find a way to create a list with columns that are invalid (code -99995)</span>
</pre></div>
</div>
</div>
</div>
<p>That’s about 2/3rds of the dataset! This data is present at a different spatial scale, but not at the 4-digit zipcode level. So, let’s just remove these columns from the dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Drop the columns you identify from the dataframe</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we will look at omitted data, with the error code -99997. Identify which columns have rows with the value -99997.<br>
⚠️ BUT don’t drop these columns from the dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Repeat the process for error code -99997</span>
</pre></div>
</div>
</div>
</div>
<p>So there are quite a few columns with data that has been omitted. But how widespread is the problem? How frequently do they appear per row? If it’s just a single no-data value every now and then, it’s not a big issue. But what about when it’s more widespread?</p>
<p>Let’s look at statistics for no-data values per row.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check rows by iterating and checking values</span>
<span class="n">rows_with_missing_count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">total_missing_values</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">gdf_cleaned</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">missing_in_row</span> <span class="o">=</span> <span class="p">(</span><span class="n">row</span> <span class="o">==</span> <span class="o">-</span><span class="mi">99997</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">missing_in_row</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">rows_with_missing_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">total_missing_values</span> <span class="o">+=</span> <span class="n">missing_in_row</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total rows with missing data:&quot;</span><span class="p">,</span> <span class="n">rows_with_missing_count</span><span class="p">)</span>

<span class="c1"># Calculate average number of missing columns per affected row</span>
<span class="k">if</span> <span class="n">rows_with_missing_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">avg_missing_per_row</span> <span class="o">=</span> <span class="n">total_missing_values</span> <span class="o">/</span> <span class="n">rows_with_missing_count</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average number of missing columns per affected row:&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">avg_missing_per_row</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No rows with missing data found.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>So, about half of the rows in the dataframe have missing data, and on average 5 rows are affected by this. That’s quite substantial, and will require a careful approach. Recall that The K-Means algorithm optimizes based on distance metrics. That is, it iterates to minimize the distance between points belonging to a certain cluster, and to maximize the distance to points outside of it. So, if we want to still use these variables, we need a numerical solution to the no-data problem.</p>
<p>Fortunately, we have a very simple heuristic to work with. We know that this omission happens for privacy reasons in small zipcode regions. In other words, we can generally assume that omitted data has very small quantities. We can therefore apply a straightforward stop-gap solution, namely to simply replace these no-data values with zeroes.</p>
<p>Building on this, we have a decision to make on whether or not we want to remove rows with excessive no-data values. Are no-data values informative or not? This is up to you as a modeller to decide. On the one hand, by our heuristic, no data-values <em>may</em> be informative, as they inform the model of the scale of the neighbourhood. On the other hand, is the size of the neighbourhood informative in itself in the clustering problem? That’s up to you to decide. In the default case we’re including them, but we’ve left some code for you to experiment with.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># # Exclude rows with more than 3 columns containing -99997</span>
<span class="c1"># no_data_mask = (gdf_cleaned == -99997).sum(axis=1) &lt;= 3</span>
<span class="c1"># gdf_filtered = gdf_cleaned[no_data_mask].copy()</span>
<span class="n">gdf_filtered</span> <span class="o">=</span> <span class="n">gdf_cleaned</span>

<span class="c1"># Replace -99997 with 0 (assumed very small quantity due to small neighbourhood size)</span>
<span class="n">numeric_cols</span> <span class="o">=</span> <span class="n">gdf_filtered</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">numeric_cols</span><span class="p">:</span>
    <span class="n">gdf_filtered</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">gdf_filtered</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="o">-</span><span class="mi">99997</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualizing">
<h2>Visualizing<a class="headerlink" href="#visualizing" title="Permalink to this heading">#</a></h2>
<p>Now that we’ve handled erroneous data from the dataframe, let’s take a moment to visualize our data. You can change the column name to visualize other columns. <code class="docutils literal notranslate"><span class="pre">gdf_filtered.keys()</span></code> gives an overview of available columns (only in Dutch, though translators can help).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Column to visualize</span>
<span class="n">col_name</span> <span class="o">=</span> <span class="s2">&quot;gemiddeldeWozWaardeWoning&quot;</span> <span class="c1"># Housing prices estimated by the govt.</span>

<span class="c1"># Check if the column exists</span>
<span class="k">if</span> <span class="n">col_name</span> <span class="ow">in</span> <span class="n">gdf_filtered</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="c1"># Convert to Web Mercator for basemap compatibility</span>
    <span class="n">gdf_filtered_3857</span> <span class="o">=</span> <span class="n">gdf_filtered</span><span class="o">.</span><span class="n">to_crs</span><span class="p">(</span><span class="n">epsg</span><span class="o">=</span><span class="mi">3857</span><span class="p">)</span> <span class="c1"># Use gpd function `.to_crs()`</span>

    <span class="c1"># Create side-by-side plots</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

    <span class="c1"># Choropleth map</span>
    <span class="n">gdf_filtered_3857</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">column</span><span class="o">=</span><span class="n">col_name</span><span class="p">,</span>
        <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span>
        <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
        <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
        <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span>
    <span class="p">)</span>
    <span class="n">ctx</span><span class="o">.</span><span class="n">add_basemap</span><span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">crs</span><span class="o">=</span><span class="n">gdf_filtered_3857</span><span class="o">.</span><span class="n">crs</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">ctx</span><span class="o">.</span><span class="n">providers</span><span class="o">.</span><span class="n">OpenStreetMap</span><span class="o">.</span><span class="n">Mapnik</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Spatial distribution of </span><span class="si">{</span><span class="n">col_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

    <span class="c1"># Histogram</span>
    <span class="n">gdf_filtered</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Distribution of </span><span class="si">{</span><span class="n">col_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">col_name</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Column &#39;</span><span class="si">{</span><span class="n">col_name</span><span class="si">}</span><span class="s2">&#39; not found in the GeoDataFrame.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice in the distribution that we have some unintended side-effects, such as zeroes in the housing price. More sophisticated methods can probably solve this, but it’s a bit beyond the scope of this short tutorial. Let your imagination run wild!</p>
<p>❗<strong>Q1: In the case presented in this tutorial, everything gets assigned to zeroes because we have prior knowledge on the structure of the underlying data. In cases where data is missing and we don’t have prior knowledge, which other solutions can you come up with to impute these values?</strong></p>
</section>
<section id="fix-non-ratio-d-columns">
<h2>Fix non-ratio’d columns<a class="headerlink" href="#fix-non-ratio-d-columns" title="Permalink to this heading">#</a></h2>
<p>Now that we have fixed our dataset, we can have a look at the actual structure of the columns. Let’s visualize a couple of rows again to inspect what kinds of values are found in each column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gdf_filtered</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><em>“Inwoner”</em> translates to “inhabitant”. Notice that we have columns with counts. If you think about how KMeans predicts, you’ll understand that these counts are not informative, because zipcode areas are not uniform in size. Instead, we should convert everything to ratios, as these can be compared between areas. Fortunately, we have total counts of everything that we should ratio. The code provided below will do this for you.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">make_ratios</span><span class="p">(</span><span class="n">gdf_to_ratio</span><span class="p">):</span>
    <span class="n">gdf_ratio</span> <span class="o">=</span> <span class="n">gdf_to_ratio</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># Otherwise we overwrite the original gdf</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="n">gdf_ratio</span><span class="o">.</span><span class="n">columns</span>

    <span class="c1"># 1. Population ratios</span>
    <span class="n">pop_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;aantalMannen&#39;</span><span class="p">,</span> <span class="s1">&#39;aantalVrouwen&#39;</span><span class="p">]</span> <span class="ow">or</span> <span class="n">col</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;aantalInwoners&#39;</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">pop_cols</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">col</span> <span class="o">!=</span> <span class="s1">&#39;aantalInwoners&#39;</span><span class="p">:</span>
            <span class="n">gdf_ratio</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">gdf_ratio</span><span class="p">[</span><span class="s1">&#39;aantalInwoners&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">gdf_ratio</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">/</span> <span class="n">gdf_ratio</span><span class="p">[</span><span class="s1">&#39;aantalInwoners&#39;</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># 2. Household ratios</span>
    <span class="n">hh_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols</span> <span class="k">if</span> <span class="s1">&#39;huishoudens&#39;</span> <span class="ow">in</span> <span class="n">col</span> <span class="ow">and</span> <span class="n">col</span> <span class="o">!=</span> <span class="s1">&#39;gemiddeldeHuishoudensgrootte&#39;</span> <span class="ow">and</span> <span class="n">col</span> <span class="o">!=</span> <span class="s1">&#39;aantalPartHuishoudens&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">hh_cols</span><span class="p">:</span>
        <span class="n">gdf_ratio</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">gdf_ratio</span><span class="p">[</span><span class="s1">&#39;aantalPartHuishoudens&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">gdf_ratio</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">/</span> <span class="n">gdf_ratio</span><span class="p">[</span><span class="s1">&#39;aantalPartHuishoudens&#39;</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># 3. Housing ratios</span>
    <span class="n">woning_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols</span> <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;aantalWoningen&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">col</span> <span class="o">!=</span> <span class="s1">&#39;aantalWoningen&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">woning_cols</span><span class="p">:</span>
        <span class="n">gdf_ratio</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">gdf_ratio</span><span class="p">[</span><span class="s1">&#39;aantalWoningen&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">gdf_ratio</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">/</span> <span class="n">gdf_ratio</span><span class="p">[</span><span class="s1">&#39;aantalWoningen&#39;</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">gdf_ratio</span>

<span class="n">gdf_ratiod</span> <span class="o">=</span> <span class="n">make_ratios</span><span class="p">(</span><span class="n">gdf_filtered</span><span class="p">)</span>
<span class="n">gdf_ratiod</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>❗<strong>Q2: How do you think that the model behave if we don’t convert columns like this? Could the model theoretically still learn ratio differences between neighbourhoods? Think hard about how K-Means classification works (distance-based optimization problem), and what transforming into ratios is supposed to solve.</strong></p>
<p><em>Simply put, the model would separate zipcode areas by the total size of the population, rather than by the relative differences between population groups. In effect, it would not use the variables in a way that we’d like them to, because we understand that demographic information is supposed to be used to compare neighbourhoods by their composition, rather than their flat counts.</em></p>
<p><em>In this case, transforming to ratios shrinks and transforms variables through divison by a given total. Realize that this process inherently transforms distance. K-Means is entirely based on minimizing and maximizing distance, and it doesn’t learn the relationship between variables. As such, if we don’t convert sub-categories to ratios, then the only meaningful signal to the model is the size of the municipality size, and not their relative differences. By turning variables into ratios, we move the focus away from the relative size of municipalities, and more so on the relationship between variables. Because K-Means does not encode (i.e. it does not learn, only solve), we need to make this information explicit, otherwise the model will focus simply on the relative inhabitant size difference between zipcode regions, and not take into account demographic distributions.</em></p>
<section id="normalizing">
<h3><strong>Normalizing</strong><a class="headerlink" href="#normalizing" title="Permalink to this heading">#</a></h3>
<p>As mentioned, KMeans models minimize a distance objective function, where the dsitance is determined by the values of the variables. This means that a variable with values in the range 100 to 1’000 will have a much stronger effect on the model’s decision boundary than a variable with values ranging from 0.0 to 1.0. As such, it’s good practice to normalize variables, so that they have the same importance to the model. To do this, we can <em>standardize</em> each variable (also called z-score normalization):</p>
<p>$$
z = \frac{x - \mu}{\sigma}
$$</p>
<p>Where:</p>
<ul class="simple">
<li><p>( x ) is the original variable value</p></li>
<li><p>( \mu ) is the mean of the variable</p></li>
<li><p>( \sigma ) is the standard deviation of the variable</p></li>
</ul>
<p>Let’s apply it to each column that we intend to include in the clustering problem.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">numeric_cols</span> <span class="o">=</span> <span class="n">gdf_ratiod</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">numeric_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">numeric_cols</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">col</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;postcode&quot;</span><span class="p">]]</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">gdf_norm</span> <span class="o">=</span> <span class="n">gdf_ratiod</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">gdf_norm</span><span class="p">[</span><span class="n">numeric_cols</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">gdf_norm</span><span class="p">[</span><span class="n">numeric_cols</span><span class="p">])</span>

<span class="n">gdf_norm</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Now, all of the values above are z-score normalized, which brings them all to the same range while still preserving meaningful differences compared to the mean of each variable.</p>
<p>❗<strong>Q3: z-score normalization isn’t the only way to normalize data. We can also normalize to a 0-1 range by min/max normalizing: <code class="docutils literal notranslate"><span class="pre">(value</span> <span class="pre">-</span> <span class="pre">min)</span> <span class="pre">/</span> <span class="pre">(max</span> <span class="pre">-</span> <span class="pre">min)</span></code>. What are the benefits and downsides of using this method of normalizing, especially compared to z-score normalization? When would it be suitable to use compared to z-score normalization?</strong></p>
</section>
</section>
</section>
<section id="clustering">
<h1>Clustering<a class="headerlink" href="#clustering" title="Permalink to this heading">#</a></h1>
<section id="running-and-evaluating-k-means-clustering">
<h2>Running and evaluating K-Means clustering<a class="headerlink" href="#running-and-evaluating-k-means-clustering" title="Permalink to this heading">#</a></h2>
<p>Now that we’ve prepared the data, we can move towards clustering it. A constant problem with unsupervised learning is deciding which model is the ‘right’ model. Numerical quantities have been invented for this, which mostly describe the quality of the optimization outcome based on the intended function of KMeans (maximize distance to out-of-cluster points, minimize distance between points within same cluster). Let’s quickly discuss these three metrics in order to understand what they’re supposed to signal.</p>
<p><strong>Inertia</strong></p>
<p>$$
\text{Inertia} = \sum_{i=1}^{k} \sum_{x \in C_i} | x - \mu_i |^2
$$</p>
<p>Where:</p>
<ul class="simple">
<li><p>( k ) is the number of clusters</p></li>
<li><p>( C_i ) is the set of points in cluster ( i )</p></li>
<li><p>( \mu_i ) is the centroid of cluster ( i )</p></li>
</ul>
<p>Inertia measures the sum of squared distances between each point and the centroid of its assigned cluster. In effect, it tells you how tightly-packed clusters are. Understand though that adding more clusters <em>always</em> reduces inertia, so it’s not just a matter of picking the lowest inertia. Usually these plots are eyeballed for the most obvious break-point with the “elbow method”, where you look at where the inertia loss from adding new clusters has diminishing returns. Yes, this is pretty subjective, but that’s a recurring theme in unsupervised learning. It’s a data exploration tool first and foremost.</p>
<p><img alt="0_aY163H0kOrBO46S-.webp" src="data:image/webp;base64,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" />
<br>
(<a class="reference external" href="https://medium.com/&#64;zalarushirajsinh07/the-elbow-method-finding-the-optimal-number-of-clusters-d297f5aeb189">Zala Rushirajsinh on Medium, 2023</a>)</p>
<p><strong>Calinski-Harabasz Index</strong></p>
<p>$$
\text{CHI} = \frac{\text{Tr}(B_k)}{\text{Tr}(W_k)} \cdot \frac{n - k}{k - 1}
$$</p>
<p>Where:</p>
<ul class="simple">
<li><p>( \text{Tr}(B_k) ) is the trace of the between-cluster dispersion matrix</p></li>
<li><p>( \text{Tr}(W_k) ) is the trace of the within-cluster dispersion matrix</p></li>
<li><p>( n ) is the number of samples</p></li>
<li><p>( k ) is the number of clusters</p></li>
</ul>
<p>The Calinski-Harabasz Index measures the ratio of between-cluster dispersion to within-cluster dispersion, adjusted for the number of clusters and data points. More simply put, it compares how far apart clusters are, compared to how compact they are.</p>
<p>Higher ratio values indicate tighter, more spread-out clusters, which means a better numerical solution. Here, we can look for diminishing returns, similar to the elbow method.</p>
<p><strong>Davies-Bouldin Index</strong>
$$
\text{DBI} = \frac{1}{k} \sum_{i=1}^{k} \max_{j \ne i} \left( \frac{\sigma_i + \sigma_j}{d_{ij}} \right)
$$</p>
<p>Where:</p>
<ul class="simple">
<li><p>( \sigma_i ) is the average distance of all points in cluster ( i ) to the centroid of cluster ( i )</p></li>
<li><p>( d_{ij} ) is the distance between the centroids of clusters ( i ) and ( j )</p></li>
<li><p>( k ) is the number of clusters</p></li>
</ul>
<p>The Davies-Bouldin index measures the average similarity between each cluster and its most similar one, where similarity is a ratio of within-cluster scatter to between-cluster separation. Simply put once again, it looks at how similarly-dispersed clusters are. Lower values are better, as the objective is to create minimal overlap between all clusters.</p>
<p>Now let’s plot these three metrics and see what we get…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_kmeans_metrics</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cluster_range</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">)):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots KMeans clustering metrics (inertia, Calinski-Harabasz, Davies-Bouldin)</span>
<span class="sd">    side-by-side for a given dataset and cluster range.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - X: ndarray or DataFrame, shape (n_samples, n_features)</span>
<span class="sd">    - cluster_range: iterable of integers, number of clusters to evaluate</span>
<span class="sd">    - filename: str, name of the output image file</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ch_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">db_scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">cluster_range</span><span class="p">:</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">inertias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>
        <span class="n">ch_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
        <span class="n">db_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cluster_range</span><span class="p">,</span> <span class="n">inertias</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Inertia (lower=better)&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of clusters&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>

    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cluster_range</span><span class="p">,</span> <span class="n">ch_scores</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Calinski-Harabasz Index (higher=better)&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of clusters&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>

    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cluster_range</span><span class="p">,</span> <span class="n">db_scores</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Davies-Bouldin Index (lower=better)&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of clusters&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">gdf_norm</span><span class="p">[</span><span class="n">numeric_cols</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">plot_kmeans_metrics</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>But wait, that’s strange? Why are these metric plots so strange? For inertia, there is no clear elbow. For CHI, cluster overlap seems to increase as we add clusters. DBI behaves erratically, with no clear best choice either (maybe 9..?)</p>
<p>Let’s have a look at the clusters that it actually produces to try to make sense of it. Let’s use k=4, since the “elbow” seems most promising here.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">gdf_norm</span><span class="p">[</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert to Web Mercator for contextily</span>
<span class="n">gdf_norm_3857</span> <span class="o">=</span> <span class="n">gdf_norm</span><span class="o">.</span><span class="n">to_crs</span><span class="p">(</span><span class="n">epsg</span><span class="o">=</span><span class="mi">3857</span><span class="p">)</span>

<span class="c1"># Plot choropleth</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">gdf_norm_3857</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">column</span><span class="o">=</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">,</span>
    <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>
<span class="n">ctx</span><span class="o">.</span><span class="n">add_basemap</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">crs</span><span class="o">=</span><span class="n">gdf_norm_3857</span><span class="o">.</span><span class="n">crs</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">ctx</span><span class="o">.</span><span class="n">providers</span><span class="o">.</span><span class="n">OpenStreetMap</span><span class="o">.</span><span class="n">Mapnik</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Neighbourhood clusters&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s have a look at the clusters that it actually produces to try to make sense of it. Let’s use k=4, since the “elbow” seems most promising here.</p>
<p>So, by our cluster metrics, the results shouldn’t necessarily be better with more clusters. However, the computed clusters seem to have clear and logical patterns, namely the degree of urbanisation within each postcode:</p>
<ol class="arabic simple">
<li><p>Areas with the Groene Hart (“green heart”, between Rotterdam and Utrecht) almost all belong to the same cluster. <strong>This cluster is shared with the more rural and less populated zipcodes</strong>.</p></li>
<li><p>Another <em>cluster captures most of the suburban</em> and less densely populated urban towns and cities.</p></li>
<li><p>Thirdly, <strong>there is a clear urbanism cluster</strong> which covers more densely-populated areas, such as Leiden, Delft, Amsterdam, Utrecht, and Rotterdam.</p></li>
<li><p><strong>The final cluster seems to be correlated with industry</strong>. In the south, Rotterdam Botlek shows up as part of this cluster, and so does Amsterdam Westpoort near Amsterdam. Both of these are shipping areas. This might have been informed by the lack of population data in this area, as these zipcodes are mostly buildings without many inhabitants, and without housing prices (as these are given for residential buildings only).</p></li>
</ol>
<p>As can be seen, unsupervised learning is essentially a way to extract key take-aways from the input variables, and a-priori you often don’t know what you’re going to get out of it.</p>
<p>❗<strong>Q4: Why does the CHI metric decrease instead of increase in this context, when seemingly logical clusters can be formed? (HINT: Think about how cities tend to form a gradient, in combination with what the CHI metric is supposed to be measuring).</strong></p>
<p>Feel free to check how the clusters change with different values of K - see if you can make sense of them still! The next section will continue with <code class="docutils literal notranslate"><span class="pre">k=4</span></code>.</p>
</section>
</section>
<section id="analysis-of-clusters">
<h1>Analysis of clusters<a class="headerlink" href="#analysis-of-clusters" title="Permalink to this heading">#</a></h1>
<p>Now that we have our clusters and a spatial understanding of what they mean, we can also attempt to understand them numerically. First, let’s make a dataframe with just the variables so that we can compute summary statistics over them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copy and clean the GeoDataFrame</span>
<span class="n">gdf_analysis</span> <span class="o">=</span> <span class="n">gdf_norm</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">gdf_analysis</span> <span class="o">=</span> <span class="n">gdf_analysis</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;geometry&#39;</span><span class="p">,</span> <span class="s1">&#39;postcode&#39;</span><span class="p">,</span> <span class="s1">&#39;gml_id&#39;</span><span class="p">,</span> <span class="s1">&#39;fuuid&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="c1"># Separate features and cluster labels</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">gdf_analysis</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">gdf_analysis</span><span class="p">[</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>With cluster-level summary statistics in place, we can have a look at the means and the trends of each variable. But wait, we have 40+ variables, how are we going to make sense of this?</p>
<p>We can use tools from supervised learning to help out here. Specifically, we can treat it as a reconstruction problem, where the label is the dependent variable, and the variables of the dataframe are independent variables used to predict it. By doing so, we can understand which of the 40+ variables are most important for splitting the space into distinct clusters. You learned how to do this last week, so let’s do this here too. We’re going to fit and train on the entire dataset at once, so do the following:</p>
<ol class="arabic simple">
<li><p>instantiate a <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> using the given number of trees</p></li>
<li><p>using <code class="docutils literal notranslate"><span class="pre">features</span></code> and <code class="docutils literal notranslate"><span class="pre">labels</span></code>, train the model</p></li>
<li><p>predict values on the training features using <code class="docutils literal notranslate"><span class="pre">rf.predict(features)</span></code></p></li>
<li><p>Calculate and print the accuracy of the model using <code class="docutils literal notranslate"><span class="pre">accuracy_score</span></code>. Simply evaluate it on <code class="docutils literal notranslate"><span class="pre">labels</span></code> and the predict</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate a `RandomForestClassifier` using `features` and `labels`</span>
<span class="c1"># Then, use `accuracy</span>
<span class="n">n_trees</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="o">...</span>
</pre></div>
</div>
</div>
</div>
<p>❗<strong>Q5: What does this perfect accuracy score mean? And why do we purposely not split the dataset into train, val, and test sets?</strong></p>
<p>Now that we have reconstructed the clusters derived with unsupervised methods, we can apply a tool you learned about last week: <em>feature importance</em>. Recall that feature importance in the context of RF models is how likely a split in a tree with this variable is to partition an example into different classes. Can you see how this translates to separability between clusters in this case?</p>
<p>❗<strong>Q6: In your own words, explain how Random Forest feature importance helps to explain which variables have the greatest influence on forming clusters.</strong></p>
<p>Now that we’ve fitted our model, we can have a look at the most important features for splitting the clusters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get feature importances from the Random Forest model</span>
<span class="c1"># Be sure to sort by the importance. It can be found in the `rf` variable</span>
<span class="c1"># Remember what you learned in last week&#39;s TAA!</span>
<span class="n">importance</span> <span class="o">=</span>

<span class="c1"># Plot feature importances</span>
<span class="c1"># Assumed to be a Pandas dataframe with column importance in order</span>
<span class="c1"># Change the code or the approach if you use a different data structure</span>
<span class="n">x_feats</span> <span class="o">=</span> <span class="n">important_features</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_feats</span> <span class="o">=</span> <span class="n">important_features</span><span class="o">.</span><span class="n">index</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_feats</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_feats</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Top 10 Feature Importances&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Importance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>You can translate these most important variables with the help of Google Translate, simply print and copy-paste the entire output:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">([</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">important_features</span><span class="o">.</span><span class="n">keys</span><span class="p">()])</span>
</pre></div>
</div>
</div>
</div>
<p>To better understand each variable, we can also look at their distribution within each cluster, to understand if a variable correlates positively, neutrally, or negatively with each cluster. Have a look at the summary plots below, and try to interpret them. Remember that these are z-score normalized variables. A positive score means an above average large quantity of the , whereas a negative z-score means that there is very little of it present.</p>
<p>Try to plot or print aggregation statistics for each cluster (mean, std, min, max) for the most important variables. HINT: Pandas has <code class="docutils literal notranslate"><span class="pre">.groupby</span></code> and <code class="docutils literal notranslate"><span class="pre">.agg</span></code> functions that would be useful for this!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot or print descriptive statistics for each important feature</span>
<span class="c1"># Again assumed to be a Pandas dataframe, but feel free to use your own approach</span>
</pre></div>
</div>
</div>
</div>
<p>Have a look at some of the means and standard deviations and try to understand how they relate to the clusters.</p>
<p>❗<strong>Q7: Which numerical conclusions are you able to derive from the clusters? Are you able to make sense of the clusters? Which trends and patterns emerge for each of these clusters based on the most important variables?</strong></p>
<ul class="simple">
<li><p><em>cluster 0 shows clear demographic trends towards modern urban dwellers. Younger, more international, more one-person households, and more densely urban.</em></p></li>
<li><p><em>Similarly, cluster 1 shows trends for suburban and peripheral living, such as more families, fewer multi-family houses, with more Dutch nationals.</em></p></li>
<li><p><em>In that sense, these results corroborate the visual analysis of the maps, although not all variables are clear and easy to explain, and it should be clear that there is still a lot of manual interpretation and implicit narrative-forming involved, with potentially contrasting narratives able to be found in the data.</em></p></li>
</ul>
</section>
<section id="wrapping-up">
<h1>Wrapping up<a class="headerlink" href="#wrapping-up" title="Permalink to this heading">#</a></h1>
<p>That concludes our general introduction to the workflow of exploration using unsupervised learning. Hopefully you now understand why unsupervised methods are quite strongly up to interpretation, but also how they can lead to surprising results and emerging patterns. You’ve learned to prepare data for unsupervised classification, some of the pre-processing decisions that you have to make before exploring, and finally the process of exploration using KMeans Clustering. You’ve learned about the metrics that you can use to analyze this type of unsupervised learning problem, but also learned how these metrics don’t always tell the full story of what the data is trying to express. Lastly, you’ve learned some methods for the post-hoc analysis of clusters, and how you can try to make sense of the main patterns for each cluster. Ultimately, unsupervised learning is an exploration tool that is only as good as its user, and ultimately it still requires human interpretation to understand what each cluster represents.</p>
<p>So go out there and cluster, but remember to be sure to explain your decisions in the clustering process!</p>
<p><strong>Bonus!</strong><br>
While coming up with this tutorial, we also used Principal Component Analysis (PCA) to try to reduce the dimensionality of the data, to see if patterns would change. Ultimately this did not matter, but we decided to keep it in to show you how PCA can be used to reduce the number of variables, which makes the prediction problem easier in case you’re dealing with the curse of dimensionality (more variables than datapoints)</p>
<section id="using-pca-to-reduce-dimensionality">
<h2>Using PCA to reduce dimensionality<a class="headerlink" href="#using-pca-to-reduce-dimensionality" title="Permalink to this heading">#</a></h2>
<p>PCA is a method that reduces the dimensionality of data by summarizing the variance (main patterns) across all variables. In that sense, it’s similar to KMeans, but its purpose is usually to reduce the number of variables, rather than to be interpreted. Here, we use PCA to reduce the total number of variables that will be used in the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Assume gdf_norm is your normalized DataFrame (numeric columns only, no geometry)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">gdf_norm</span><span class="p">[</span><span class="n">numeric_cols</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># or the columns you want to use</span>

<span class="c1"># Fit PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">()</span>
<span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Plot cumulative explained variance</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">),</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative explained variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;PCA: Cumulative Explained Variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Based on the above plot, you pick the number of components. Usually you pick a number of components that explain ~90% of the variance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">12</span>

<span class="c1"># Reduce data to n_components</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">)</span>
<span class="n">X_reduced</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="re-run-and-re-interpret">
<h3>Re-run and re-interpret<a class="headerlink" href="#re-run-and-re-interpret" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_kmeans_metrics</span><span class="p">(</span><span class="n">X_reduced</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The patterns in the plots haven’t changed in a meaningful manner, which indicates that PCA doesn’t do much to generate better separable clusters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X_reduced</span><span class="p">)</span>

<span class="n">gdf_norm</span><span class="p">[</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert to Web Mercator for contextily</span>
<span class="n">gdf_norm_3857</span> <span class="o">=</span> <span class="n">gdf_norm</span><span class="o">.</span><span class="n">to_crs</span><span class="p">(</span><span class="n">epsg</span><span class="o">=</span><span class="mi">3857</span><span class="p">)</span>

<span class="c1"># Plot choropleth</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">gdf_norm_3857</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">column</span><span class="o">=</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">,</span>
    <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>
<span class="n">ctx</span><span class="o">.</span><span class="n">add_basemap</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">crs</span><span class="o">=</span><span class="n">gdf_norm_3857</span><span class="o">.</span><span class="n">crs</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">ctx</span><span class="o">.</span><span class="n">providers</span><span class="o">.</span><span class="n">OpenStreetMap</span><span class="o">.</span><span class="n">Mapnik</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Neighbourhood clusters&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Here we can see that the main patterns are still the same, and the PCA hasn’t resulted in any meaningful shifts. However, if we would have a problem with many more variables than rows, PCA could be used to generate more meaningful clusters.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./TAA4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="lecture.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lecture: Loading API geodata and clustering</p>
      </div>
    </a>
    <a class="right-next"
       href="../TAA5/tutorial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">TAA5: Accessibility to healthcare facilities</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">TAA4: Unsupervised learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#important-before-we-start">Important before we start</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#packages">Packages</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-preparation">Dataset preparation</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-data-for-the-randstad-area">Load data for the Randstad area</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handle-missing-data">Handle missing data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing">Visualizing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fix-non-ratio-d-columns">Fix non-ratio’d columns</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#normalizing"><strong>Normalizing</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering">Clustering</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-and-evaluating-k-means-clustering">Running and evaluating K-Means clustering</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis-of-clusters">Analysis of clusters</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#wrapping-up">Wrapping up</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-pca-to-reduce-dimensionality">Using PCA to reduce dimensionality</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#re-run-and-re-interpret">Re-run and re-interpret</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Elco Koks & Dr Alex Levering
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>